{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89205333-6a74-4768-bf66-b3035bdc02f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0d124798-5543-4703-a5fb-7b2892a1a46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmenta√ß√£o conclu√≠da! Pastas:\n",
      "  TextBasedWave/chars_by_class\\train\n",
      "  TextBasedWave/chars_by_class\\val\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_character_boxes(img, min_width=5, min_height=10):\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, bw = cv2.threshold(gray, 0, 255,\n",
    "                         cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "    opened = cv2.morphologyEx(bw, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    contours, _ = cv2.findContours(opened, cv2.RETR_EXTERNAL,\n",
    "                                   cv2.CHAIN_APPROX_SIMPLE)\n",
    "    boxes = []\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if w >= min_width and h >= min_height:\n",
    "            boxes.append((x, y, w, h))\n",
    "    return sorted(boxes, key=lambda b: b[0])\n",
    "\n",
    "\n",
    "def get_fixed_boxes(img, num_chars, min_width=5, min_height=10):\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "    slice_w = w // num_chars\n",
    "    boxes = []\n",
    "    for i in range(num_chars):\n",
    "        x1 = i * slice_w\n",
    "        x2 = w if i == num_chars - 1 else (i + 1) * slice_w\n",
    "        w_box = x2 - x1\n",
    "        if w_box >= min_width and h >= min_height:\n",
    "            boxes.append((x1, 0, w_box, h))\n",
    "    return boxes\n",
    "\n",
    "\n",
    "def normalize_and_pad(crop, size=32, border_color=(255,255,255)):\n",
    "\n",
    "    h0, w0 = crop.shape[:2]\n",
    "    # escala para caber em size\n",
    "    scale = min(size / h0, size / w0)\n",
    "    new_w, new_h = int(w0 * scale), int(h0 * scale)\n",
    "    # evita zero\n",
    "    new_w = max(1, new_w)\n",
    "    new_h = max(1, new_h)\n",
    "    resized = cv2.resize(crop, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "    # calcula padding\n",
    "    delta_w = size - new_w\n",
    "    delta_h = size - new_h\n",
    "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
    "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
    "    padded = cv2.copyMakeBorder(resized, top, bottom, left, right,\n",
    "                                cv2.BORDER_CONSTANT, value=list(border_color))\n",
    "    return padded\n",
    "\n",
    "\n",
    "def segment_and_save_split(csv_path, img_dir, output_base_dir,\n",
    "                           train_ratio=0.8, max_width=25, seed=42):\n",
    "\n",
    "    random.seed(42)\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Cria pastas para splits e classes\n",
    "    classes = sorted({c for lbl in df['label'].astype(str) for c in lbl})\n",
    "    for split in ('train', 'val'):\n",
    "        for char in classes:\n",
    "            os.makedirs(os.path.join(output_base_dir, split, char), exist_ok=True)\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        fname = row['filename']\n",
    "        label = str(row['label'])\n",
    "        img_path = os.path.join(img_dir, fname)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"Aviso: n√£o encontrei {img_path}\")\n",
    "            continue\n",
    "\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "        # Escolhe split\n",
    "        split = 'train' if random.random() < train_ratio else 'val'\n",
    "\n",
    "        # Tenta segmenta√ß√£o por contornos\n",
    "        boxes = get_character_boxes(img)\n",
    "        # Se n√£o bate com o n√∫mero de caracteres, usa divis√£o fixa\n",
    "        if len(boxes) != len(label):\n",
    "            boxes = get_fixed_boxes(img, len(label))\n",
    "\n",
    "        # Salva crops filtrando largura m√°xima e padronizando tamanho\n",
    "        for i, ((x, y, w, h), char) in enumerate(zip(boxes, label)):\n",
    "            crop = img_gray[y:y+h, x:x+w]\n",
    "            norm_crop = normalize_and_pad(crop, size=32, border_color=(255,255,255))\n",
    "            char_dir = os.path.join(output_base_dir, split, char)\n",
    "            base, _ = os.path.splitext(fname)\n",
    "            out_name = f\"{base}_{i:02d}.png\"\n",
    "            cv2.imwrite(os.path.join(char_dir, out_name), norm_crop)\n",
    "\n",
    "    print(f\"Segmenta√ß√£o conclu√≠da! Pastas:\")\n",
    "    print(f\"  {os.path.join(output_base_dir, 'train')}\")\n",
    "    print(f\"  {os.path.join(output_base_dir, 'val')}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    CSV_PATH = 'TextBasedWave/train.csv'\n",
    "    IMG_DIR  = 'TextBasedWave/train'\n",
    "    OUT_DIR  = 'TextBasedWave/chars_by_class'\n",
    "    segment_and_save_split(CSV_PATH, IMG_DIR, OUT_DIR,\n",
    "                           train_ratio=0.8, max_width=25, seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28273e77-d840-4465-b239-f1eee3114877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 01  Loss=3.036  TrainAcc=0.179  ValAcc=0.354\n",
      "Ep 02  Loss=2.171  TrainAcc=0.455  ValAcc=0.498\n",
      "Ep 03  Loss=1.909  TrainAcc=0.539  ValAcc=0.537\n",
      "Ep 04  Loss=1.775  TrainAcc=0.571  ValAcc=0.549\n",
      "Ep 05  Loss=1.683  TrainAcc=0.591  ValAcc=0.554\n",
      "Ep 06  Loss=1.601  TrainAcc=0.606  ValAcc=0.558\n",
      "Ep 07  Loss=1.519  TrainAcc=0.623  ValAcc=0.558\n",
      "Ep 08  Loss=1.453  TrainAcc=0.638  ValAcc=0.567\n",
      "Ep 09  Loss=1.374  TrainAcc=0.650  ValAcc=0.563\n",
      "Ep 10  Loss=1.301  TrainAcc=0.666  ValAcc=0.565\n",
      "Ep 11  Loss=1.224  TrainAcc=0.683  ValAcc=0.564\n",
      "Ep 12  Loss=1.149  TrainAcc=0.699  ValAcc=0.567\n",
      "Ep 13  Loss=1.077  TrainAcc=0.713  ValAcc=0.564\n",
      "Ep 14  Loss=1.009  TrainAcc=0.730  ValAcc=0.558\n",
      "Ep 15  Loss=0.930  TrainAcc=0.751  ValAcc=0.562\n",
      "Ep 16  Loss=0.862  TrainAcc=0.770  ValAcc=0.555\n",
      "Ep 17  Loss=0.803  TrainAcc=0.785  ValAcc=0.548\n",
      "Ep 18  Loss=0.819  TrainAcc=0.777  ValAcc=0.553\n",
      "Ep 19  Loss=0.708  TrainAcc=0.809  ValAcc=0.546\n",
      "Ep 20  Loss=0.648  TrainAcc=0.830  ValAcc=0.546\n",
      "Modelo salvo em: models\\charcnn_lstm.pt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Configura√ß√µes ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "DEVICE      = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ALPHABET    = \"abcdefghijklmnopqrstuvwxyz0123456789\"\n",
    "NUM_CLASSES = len(ALPHABET)\n",
    "BATCH_SIZE  = 64\n",
    "EPOCHS      = 20\n",
    "LR          = 1e-3\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Transforms ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "val_tf = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Datasets & Loaders ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "train_ds = ImageFolder(\"TextBased/chars_by_class/train\", transform=train_tf)\n",
    "val_ds   = ImageFolder(\"TextBased/chars_by_class/val\",   transform=val_tf)\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=4)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Modelo CNN + LSTM ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "class CharCNN_LSTM(nn.Module):\n",
    "    def __init__(self, num_classes, lstm_hidden=256):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),              # 32‚Üí16\n",
    "            nn.Conv2d(64,128,3,padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2)               # 16‚Üí8\n",
    "        )\n",
    "        self.lstm = nn.LSTM(input_size=128*8,\n",
    "                            hidden_size=lstm_hidden,\n",
    "                            batch_first=True)\n",
    "        self.classifier = nn.Linear(lstm_hidden, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.cnn(x)              # [B,128,8,8]\n",
    "        B, C, H, W = feat.size()\n",
    "        seq = feat.permute(0,3,1,2).contiguous().view(B, W, C*H)\n",
    "        out, (hn, cn) = self.lstm(seq)  # [B, W, lstm_hidden]\n",
    "        last = out[:, -1, :]\n",
    "        return self.classifier(last)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Instancia√ß√£o ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "model     = CharCNN_LSTM(NUM_CLASSES).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Loop de Treino/Valida√ß√£o ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    running_loss, total, correct = 0, 0, 0\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(imgs)\n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        preds = out.argmax(1)\n",
    "        total   += labels.size(0)\n",
    "        correct += (preds == labels).sum().item()\n",
    "    train_acc = correct/total\n",
    "\n",
    "    model.eval()\n",
    "    v_total, v_correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "            out = model(imgs)\n",
    "            preds = out.argmax(1)\n",
    "            v_total   += labels.size(0)\n",
    "            v_correct += (preds == labels).sum().item()\n",
    "    val_acc = v_correct / v_total\n",
    "\n",
    "    print(f\"Ep {epoch:02d}  Loss={running_loss/len(train_loader):.3f}  \"\n",
    "          f\"TrainAcc={train_acc:.3f}  ValAcc={val_acc:.3f}\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Salvando o modelo ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "save_path = os.path.join(\"models\", \"charcnn_lstm.pt\")\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"Modelo salvo em: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a7e9345-a938-4566-8fc1-60069863b790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processamento de segmenta√ß√£o e padding conclu√≠do.\n"
     ]
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ‚îÄ Configura√ß√µes ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "VAL_DIR     = \"TextBased/val\"          # Pasta com CAPTCHAs originais\n",
    "OUTPUT_DIR  = \"TextBased/segments\"     # Pasta raiz onde cada imagem ter√° sua pr√≥pria pasta\n",
    "MIN_W, MIN_H = 5, 10                   # Tamanho m√≠nimo de cada segmento\n",
    "SPLIT_W     = 30                       # Largura acima da qual dividimos em dois\n",
    "TARGET_SIZE = 32                       # tamanho final com padding\n",
    "\n",
    "def get_character_boxes(img, min_w=MIN_W, min_h=MIN_H):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, bw = cv2.threshold(gray, 0, 255,\n",
    "                         cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "    opened = cv2.morphologyEx(bw, cv2.MORPH_OPEN, kernel)\n",
    "    cnts, _ = cv2.findContours(opened, cv2.RETR_EXTERNAL,\n",
    "                               cv2.CHAIN_APPROX_SIMPLE)\n",
    "    boxes = [\n",
    "        (x, y, w, h)\n",
    "        for c in cnts\n",
    "        for x, y, w, h in [cv2.boundingRect(c)]\n",
    "        if w >= min_w and h >= min_h\n",
    "    ]\n",
    "    return sorted(boxes, key=lambda b: b[0])\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Loop sobre cada CAPTCHA ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "for fname in sorted(os.listdir(VAL_DIR)):\n",
    "    name, ext = os.path.splitext(fname)\n",
    "    img_path = os.path.join(VAL_DIR, fname)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(f\"[ERRO] n√£o foi poss√≠vel ler {fname}\")\n",
    "        continue\n",
    "\n",
    "    boxes = get_character_boxes(img)\n",
    "    crops = []\n",
    "    for (x, y, w, h) in boxes:\n",
    "        if w > SPLIT_W:\n",
    "            mid = w // 2\n",
    "            crops.append(img[y:y+h, x    :x+mid])\n",
    "            crops.append(img[y:y+h, x+mid:x+w])\n",
    "        else:\n",
    "            crops.append(img[y:y+h, x:x+w])\n",
    "\n",
    "    # s√≥ continua se bate com o nome\n",
    "    if len(crops) != len(name):\n",
    "        continue\n",
    "\n",
    "    out_folder = os.path.join(OUTPUT_DIR, name)\n",
    "    os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "    for idx, crop in enumerate(crops, start=1):\n",
    "        h, w = crop.shape[:2]\n",
    "\n",
    "        # 1) redimensiona se maior que TARGET_SIZE, mantendo propor√ß√£o\n",
    "        scale = min(1.0, TARGET_SIZE / h, TARGET_SIZE / w)\n",
    "        new_w, new_h = int(w * scale), int(h * scale)\n",
    "        if scale < 1.0:\n",
    "            crop = cv2.resize(crop, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "        else:\n",
    "            new_w, new_h = w, h\n",
    "\n",
    "        # 2) cria canvas branco 32√ó32\n",
    "        canvas = np.ones((TARGET_SIZE, TARGET_SIZE, 3), dtype=crop.dtype) * 255\n",
    "\n",
    "        # 3) centraliza\n",
    "        y_off = (TARGET_SIZE - new_h) // 2\n",
    "        x_off = (TARGET_SIZE - new_w) // 2\n",
    "        canvas[y_off:y_off+new_h, x_off:x_off+new_w] = crop\n",
    "\n",
    "        # 4) salva\n",
    "        out_path = os.path.join(out_folder, f\"{idx:02d}.png\")\n",
    "        cv2.imwrite(out_path, canvas)\n",
    "\n",
    "print(\"Processamento de segmenta√ß√£o e padding conclu√≠do.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1eca366-6d53-4e99-abbd-56db44a16240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia de sequ√™ncia (todas as letras corretas): 3076/3745 = 82.14%\n",
      "Acur√°cia de caractere (individual): 17928/18725 = 95.74%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "# ‚îÄ‚îÄ Configura√ß√µes ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "BASE_FOLDER    = \"TextBased/segments\"\n",
    "MODEL_PATH     = \"models/charcnn_lstm.pt\"\n",
    "DEVICE         = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "EXTENSIONS     = (\".png\", \".jpg\", \".jpeg\")\n",
    "\n",
    "# ‚îÄ‚îÄ Carrega modelo ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "model = CharCNN_LSTM(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "# ‚îÄ‚îÄ √çndice‚Üír√≥tulo ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "train_ds    = ImageFolder(\"TextBased/chars_by_class/train\", transform=train_tf)\n",
    "class_names = train_ds.classes\n",
    "\n",
    "# ‚îÄ‚îÄ Transform de infer√™ncia ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "infer_tf = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "def prepare_img(gray_np):\n",
    "    return infer_tf(gray_np)\n",
    "\n",
    "# ‚îÄ‚îÄ Inicializa contadores ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "total_sequences        = 0\n",
    "correct_sequences      = 0\n",
    "overall_char_correct   = 0\n",
    "overall_char_total     = 0\n",
    "\n",
    "# ‚îÄ‚îÄ Loop em cada CAPTCHA (pasta) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "for label in sorted(os.listdir(BASE_FOLDER)):\n",
    "    folder = os.path.join(BASE_FOLDER, label)\n",
    "    if not os.path.isdir(folder):\n",
    "        continue\n",
    "\n",
    "    total_sequences += 1\n",
    "    seq_correct = 0\n",
    "    seq_total   = 0\n",
    "\n",
    "    # percorre os segmentos dessa pasta\n",
    "    for fname in sorted(os.listdir(folder)):\n",
    "        if not fname.lower().endswith(EXTENSIONS):\n",
    "            continue\n",
    "\n",
    "        # determina o caractere ‚Äúverdadeiro‚Äù pelo √≠ndice do arquivo\n",
    "        seg_idx   = int(os.path.splitext(fname)[0]) - 1\n",
    "        true_char = label[seg_idx]\n",
    "\n",
    "        # infer√™ncia\n",
    "        gray      = cv2.imread(os.path.join(folder, fname), cv2.IMREAD_GRAYSCALE)\n",
    "        inp       = prepare_img(gray).unsqueeze(0).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            out       = model(inp)\n",
    "            pred_char = class_names[out.argmax(dim=1).item()]\n",
    "\n",
    "        # atualiza contagens de segmento\n",
    "        is_corr = (pred_char == true_char)\n",
    "        seq_correct += is_corr\n",
    "        seq_total   += 1\n",
    "        overall_char_correct += is_corr\n",
    "        overall_char_total   += 1\n",
    "\n",
    "    # se todos os segmentos ficaram corretos, conta como sequ√™ncia certa\n",
    "    if seq_correct == seq_total and seq_total > 0:\n",
    "        correct_sequences += 1\n",
    "\n",
    "# ‚îÄ‚îÄ C√°lculo das m√©tricas ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "sequence_accuracy  = correct_sequences / total_sequences if total_sequences else 0\n",
    "character_accuracy = overall_char_correct / overall_char_total if overall_char_total else 0\n",
    "\n",
    "# ‚îÄ‚îÄ Impress√£o dos resultados ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "print(f\"Acur√°cia de sequ√™ncia (todas as letras corretas): \"\n",
    "      f\"{correct_sequences}/{total_sequences} = {sequence_accuracy:.2%}\")\n",
    "print(f\"Acur√°cia de caractere (individual): \"\n",
    "      f\"{overall_char_correct}/{overall_char_total} = {character_accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb01663-1cd8-4f16-bd61-ff7bfc5e4700",
   "metadata": {},
   "source": [
    "# Treinamento YOLO segmenta√ß√£o + classifica√ß√£o de caracteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32aa8784-918c-40c2-8947-dfcb74f1cfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ Configura√ß√µes ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "BASE_FOLDER    = \"C:/Users/joao_/captcha/TextBased/segments\"\n",
    "DATA_DIR       = \"../TextBased/chars_by_class\"              # seu diret√≥rio de treino\n",
    "PROJECT        = \"../runs/captcha_yolo\"\n",
    "EXP_NAME       = \"exp\"\n",
    "DEVICE         = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "EXTENSIONS     = (\".png\", \".jpg\", \".jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b7e02f-926f-4e0c-8053-854aea44a088",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolo11n-cls')\n",
    "\n",
    "model.train(\n",
    "    data=DATA_DIR,\n",
    "    epochs=50,\n",
    "    imgsz=32,\n",
    "    batch=64,\n",
    "    lrf=1e-3,\n",
    "    project=PROJECT,\n",
    "    name=EXP_NAME\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb4714b1-e7f9-4381-aa68-e3bd6793cfb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia de sequ√™ncia (tudo certo): 3175/3745 = 84.78%\n",
      "Acur√°cia de caractere (isolado):   18071/18725 = 96.51%\n"
     ]
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ 2) CARREGA O MODELO TREINADO ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "best_weight = os.path.join(PROJECT, EXP_NAME, \"weights\", \"best.pt\")\n",
    "\n",
    "model = YOLO(best_weight)\n",
    "\n",
    "class_names = [model.names[i] for i in sorted(model.names)]\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ Fun√ß√£o de predi√ß√£o para cada segmento ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "\n",
    "def predict_char(segment_path):\n",
    "    results = model.predict(\n",
    "        source=segment_path,\n",
    "        imgsz=32,\n",
    "        device=DEVICE,\n",
    "        verbose=False\n",
    "    )\n",
    "    # 1) acessa o tensor interno (torch.Tensor)\n",
    "    probs_tensor = results[0].probs.data  \n",
    "    # 2) move pra CPU e converte pra numpy de verdade\n",
    "    probs_array  = probs_tensor.cpu().numpy()  \n",
    "    # 3) pega o √≠ndice do valor m√°ximo\n",
    "    idx = int(probs_array.argmax())\n",
    "    # 4) retorna o nome da classe\n",
    "    return class_names[idx]\n",
    "\n",
    "# ‚îÄ‚îÄ 3) INFER√äNCIA & M√âTRICAS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "total_seq      = 0  # n√∫mero de pastas processadas\n",
    "correct_seq    = 0  # quantas tiveram todos os segmentos corretos\n",
    "total_chars    = 0  # total de segmentos\n",
    "correct_chars  = 0  # total de segmentos corretos\n",
    "\n",
    "for label in sorted(os.listdir(BASE_FOLDER)):\n",
    "    folder = os.path.join(BASE_FOLDER, label)\n",
    "    if not os.path.isdir(folder):\n",
    "        continue\n",
    "\n",
    "    total_seq += 1\n",
    "    seq_preds = []\n",
    "\n",
    "    # percorre cada arquivo de segmento\n",
    "    for fname in sorted(os.listdir(folder)):\n",
    "        if not fname.lower().endswith(EXTENSIONS):\n",
    "            continue\n",
    "\n",
    "        seg_idx   = int(os.path.splitext(fname)[0]) - 1\n",
    "        true_char = label[seg_idx]\n",
    "\n",
    "        path      = os.path.join(folder, fname)\n",
    "        pred_char = predict_char(path)\n",
    "\n",
    "        seq_preds.append((true_char, pred_char))\n",
    "        total_chars += 1\n",
    "        if pred_char == true_char:\n",
    "            correct_chars += 1\n",
    "\n",
    "    # se todos os pares (true,pred) baterem ‚Üí sequ√™ncia correta\n",
    "    if all(t == p for t, p in seq_preds) and seq_preds:\n",
    "        correct_seq += 1\n",
    "\n",
    "# ‚îÄ‚îÄ 4) RESULTADOS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "seq_acc  = correct_seq / total_seq    if total_seq  else 0\n",
    "char_acc = correct_chars / total_chars if total_chars else 0\n",
    "\n",
    "print(f\"Acur√°cia de sequ√™ncia (tudo certo): {correct_seq}/{total_seq} = {seq_acc:.2%}\")\n",
    "print(f\"Acur√°cia de caractere (isolado):   {correct_chars}/{total_chars} = {char_acc:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1306de8-7b05-4b47-a345-d004fab7f0b5",
   "metadata": {},
   "source": [
    "# Treinamento com ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d929e963-7aae-4525-853d-66d45ad9b208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# ‚îÄ‚îÄ 0) Defina DATA_DIR e carregue o dataset para descobrir num_classes ‚îÄ‚îÄ\n",
    "DATA_DIR = \"C:/Users/joao_/captcha/TextBased/chars_by_class\"\n",
    "train_tf = transforms.Compose([transforms.Resize((64,64)),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize([0.485,0.456,0.406],\n",
    "                                                    [0.229,0.224,0.225])])\n",
    "train_ds = datasets.ImageFolder(os.path.join(DATA_DIR, \"train\"), transform=train_tf)\n",
    "num_classes = len(train_ds.classes)  # ex: 36\n",
    "\n",
    "# ‚îÄ‚îÄ 1) Defini√ß√£o da classe sem usar valor padr√£o indefinido ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "class TemporalResNet50(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(TemporalResNet50, self).__init__()\n",
    "        base_model = models.resnet50()\n",
    "        self.backbone = nn.Sequential(*list(base_model.children())[:-2])\n",
    "        self.lstm     = nn.LSTM(input_size=2048, hidden_size=256,\n",
    "                                 num_layers=1, batch_first=True,\n",
    "                                 bidirectional=True)\n",
    "        self.classifier = nn.Linear(256 * 2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)          # [B, 2048, H, W]\n",
    "        b, c, h, w = x.size()\n",
    "        x = x.permute(0, 2, 3, 1).contiguous()  # [B, H, W, C]\n",
    "        x = x.view(b, h * w, c)                # [B, T, C]\n",
    "        x, _ = self.lstm(x)                    # [B, T, 512]\n",
    "        x = x[:, -1, :]                        # √∫ltimo timestep\n",
    "        return self.classifier(x)\n",
    "\n",
    "# ‚îÄ‚îÄ 2) Instancie o modelo passando num_classes ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TemporalResNet50(num_classes=num_classes).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2f9255-c7aa-487b-bfbc-480271dd73c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ C√âLULA: TREINAMENTO DO TemporalResNet50 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ‚îÄ‚îÄ Configura√ß√µes ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "DATA_DIR      = \"C:/Users/joao_/captcha/TextBased/chars_by_class\"                # estrutura: chars_by_class/train e chars_by_class/val\n",
    "PROJECT       = \"models/captcha_resnet50\"\n",
    "EXP_NAME      = \"exp\"\n",
    "DEVICE        = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "num_epochs    = 50\n",
    "batch_size    = 64\n",
    "learning_rate = 1e-3\n",
    "patience      = 15\n",
    "gamma         = 0.97    # para ExponentialLR\n",
    "\n",
    "# ‚îÄ‚îÄ Transforms ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "])\n",
    "val_tf   = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "# ‚îÄ‚îÄ Datasets & DataLoaders ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "train_ds   = datasets.ImageFolder(os.path.join(DATA_DIR, \"train\"), transform=train_tf)\n",
    "val_ds     = datasets.ImageFolder(os.path.join(DATA_DIR, \"val\"),   transform=val_tf)\n",
    "trainloader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=4, pin_memory=True)\n",
    "testloader  = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# ‚îÄ‚îÄ Diret√≥rios de sa√≠da ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "weights_dir = os.path.join(PROJECT, EXP_NAME, \"weights\")\n",
    "os.makedirs(weights_dir, exist_ok=True)\n",
    "\n",
    "# ‚îÄ‚îÄ Modelo, Otimizador, Scheduler, Crit√©rio ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "model     = TemporalResNet50(num_classes=len(train_ds.classes)).to(DEVICE)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# ‚îÄ‚îÄ Loop de Treino com Early Stopping ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "best_val_acc     = 0.0\n",
    "epochs_no_improve = 0\n",
    "best_state_dict  = None\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    running_loss, running_corrects, running_total = 0.0, 0, 0\n",
    "    \n",
    "    for images, labels in tqdm(trainloader, desc=f\"[Epoch {epoch}] Treino\", leave=False):\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss     += loss.item() * images.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        running_corrects += (preds == labels).sum().item()\n",
    "        running_total    += labels.size(0)\n",
    "    \n",
    "    train_loss = running_loss / running_total\n",
    "    train_acc  = 100 * running_corrects / running_total\n",
    "    \n",
    "    # --- Valida√ß√£o ---\n",
    "    model.eval()\n",
    "    val_corrects, val_total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(testloader, desc=f\"[Epoch {epoch}] Valida√ß√£o\", leave=False):\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            val_corrects += (preds == labels).sum().item()\n",
    "            val_total    += labels.size(0)\n",
    "    \n",
    "    val_acc = 100 * val_corrects / val_total\n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch:2d} | \"\n",
    "          f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | \"\n",
    "          f\"Val Acc: {val_acc:.2f}%\")\n",
    "    \n",
    "    # Early Stopping\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc      = val_acc\n",
    "        epochs_no_improve = 0\n",
    "        best_state_dict   = model.state_dict()\n",
    "        torch.save(best_state_dict, os.path.join(weights_dir, \"best.pth\"))\n",
    "        print(f\"üìà Nova melhor Val Acc: {best_val_acc:.2f}% ‚Äî modelo salvo.\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"‚è∏Ô∏è Sem melhora por {epochs_no_improve} √©poca(s).\")\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"üõë Early stopping ativado ap√≥s {patience} √©pocas sem melhora.\")\n",
    "            break\n",
    "\n",
    "# ‚îÄ‚îÄ Restaurar melhor modelo ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "model.load_state_dict(best_state_dict)\n",
    "print(\"‚úîÔ∏è Treinamento conclu√≠do. Melhor modelo carregado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b9e19de-19e5-41e6-addc-0fe1a931108e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia de sequ√™ncia (tudo certo): 2409/3745 = 64.33%\n",
      "Acur√°cia de caractere (isolado):   16952/18725 = 90.53%\n"
     ]
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ C√âLULA: VALIDA√á√ÉO SEGMENTO-A-SEGMENTO COM TemporalResNet50 ‚îÄ‚îÄ\n",
    "\n",
    "# ‚îÄ‚îÄ 1) Configura√ß√µes ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "BASE_FOLDER    = \"TextBased/segments\"               # pastas com r√≥tulos de sequ√™ncia\n",
    "EXTENSIONS     = (\".png\", \".jpg\", \".jpeg\")\n",
    "best_model_path = \"models/ResNet_TextBase.pth\"         # ajuste para o seu caminho\n",
    "device         = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ‚îÄ‚îÄ 2) Carrega o modelo treinado ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "model = TemporalResNet50(num_classes=num_classes).to(device)\n",
    "model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# ‚îÄ‚îÄ 3) Transforms de valida√ß√£o (mesmo padr√£o do treino) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "val_tf = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                         std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "# ‚îÄ‚îÄ 4) Fun√ß√£o de predi√ß√£o para um segmento ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def predict_char(segment_path):\n",
    "    img = Image.open(segment_path).convert(\"RGB\")\n",
    "    x   = val_tf(img).unsqueeze(0).to(device)            # [1,C,H,W]\n",
    "    with torch.no_grad():\n",
    "        logits = model(x)                                # [1,num_classes]\n",
    "        idx    = int(logits.argmax(dim=1).cpu().item())\n",
    "    return train_ds.classes[idx]                         # lista de classes do ImageFolder\n",
    "\n",
    "# ‚îÄ‚îÄ 5) Infer√™ncia & m√©tricas ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "total_seq     = 0   # total de sequ√™ncias (pastas)\n",
    "correct_seq   = 0   # quantas sequ√™ncias tiveram TODOS os chars corretos\n",
    "total_chars   = 0   # total de segmentos avaliados\n",
    "correct_chars = 0   # total de segmentos corretos\n",
    "\n",
    "for label in sorted(os.listdir(BASE_FOLDER)):\n",
    "    folder = os.path.join(BASE_FOLDER, label)\n",
    "    if not os.path.isdir(folder):\n",
    "        continue\n",
    "\n",
    "    total_seq += 1\n",
    "    seq_preds = []\n",
    "\n",
    "    for fname in sorted(os.listdir(folder)):\n",
    "        if not fname.lower().endswith(EXTENSIONS):\n",
    "            continue\n",
    "\n",
    "        seg_idx    = int(os.path.splitext(fname)[0]) - 1\n",
    "        true_char  = label[seg_idx]\n",
    "        path       = os.path.join(folder, fname)\n",
    "        pred_char  = predict_char(path)\n",
    "\n",
    "        seq_preds.append((true_char, pred_char))\n",
    "        total_chars += 1\n",
    "        if pred_char == true_char:\n",
    "            correct_chars += 1\n",
    "\n",
    "    if seq_preds and all(t == p for t, p in seq_preds):\n",
    "        correct_seq += 1\n",
    "\n",
    "# ‚îÄ‚îÄ 6) Resultados ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "seq_acc  = correct_seq   / total_seq   if total_seq   else 0\n",
    "char_acc = correct_chars / total_chars if total_chars else 0\n",
    "\n",
    "print(f\"Acur√°cia de sequ√™ncia (tudo certo): {correct_seq}/{total_seq} = {seq_acc:.2%}\")\n",
    "print(f\"Acur√°cia de caractere (isolado):   {correct_chars}/{total_chars} = {char_acc:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a69e6af-85be-40f4-9bb7-10d60e52a693",
   "metadata": {},
   "source": [
    "# Teste com Dataset com Wave Distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "819d5740-1393-4ebb-86fd-665e0bb1f0c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] O sistema n√£o pode encontrar o caminho especificado: 'C:/Users/joao_/captcha/TextBasedWave/chars_by_class'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m random\u001b[38;5;241m.\u001b[39mseed(RANDOM_SEED)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Coletar todas as imagens por classe\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m class_dirs \u001b[38;5;241m=\u001b[39m [d \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBASE_DIR\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(BASE_DIR, d)) \u001b[38;5;129;01mand\u001b[39;00m d \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m SPLITS]\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Preparar estrutura de pastas\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m SPLITS:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] O sistema n√£o pode encontrar o caminho especificado: 'C:/Users/joao_/captcha/TextBasedWave/chars_by_class'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "\n",
    "# Par√¢metros\n",
    "BASE_DIR      = \"C:/Users/joao_/captcha/TextBasedWave/chars_by_class\"\n",
    "SPLITS        = ['train', 'val']\n",
    "TRAIN_RATIO   = 0.8\n",
    "RANDOM_SEED   = 42\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "# Coletar todas as imagens por classe\n",
    "class_dirs = [d for d in os.listdir(BASE_DIR) if os.path.isdir(os.path.join(BASE_DIR, d)) and d not in SPLITS]\n",
    "\n",
    "# Preparar estrutura de pastas\n",
    "for split in SPLITS:\n",
    "    for cls in class_dirs:\n",
    "        os.makedirs(os.path.join(BASE_DIR, split, cls), exist_ok=True)\n",
    "\n",
    "# Divis√£o train/val\n",
    "for cls in class_dirs:\n",
    "    cls_dir = os.path.join(BASE_DIR, cls)\n",
    "    images  = [f for f in os.listdir(cls_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    random.shuffle(images)\n",
    "\n",
    "    split_idx = int(len(images) * TRAIN_RATIO)\n",
    "    train_imgs = images[:split_idx]\n",
    "    val_imgs   = images[split_idx:]\n",
    "\n",
    "    for fname in train_imgs:\n",
    "        src = os.path.join(cls_dir, fname)\n",
    "        dst = os.path.join(BASE_DIR, 'train', cls, fname)\n",
    "        shutil.move(src, dst)\n",
    "\n",
    "    for fname in val_imgs:\n",
    "        src = os.path.join(cls_dir, fname)\n",
    "        dst = os.path.join(BASE_DIR, 'val', cls, fname)\n",
    "        shutil.move(src, dst)\n",
    "\n",
    "    # Remove pasta antiga da classe\n",
    "    os.rmdir(cls_dir)\n",
    "\n",
    "print(\"‚úÖ Divis√£o finalizada: 80% treino, 20% valida√ß√£o em subpastas por classe.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307f8541-aaeb-40e2-8183-50fc0a5a5114",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Configura√ß√µes ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "DEVICE      = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ALPHABET    = \"abcdefghijklmnopqrstuvwxyz0123456789\"\n",
    "NUM_CLASSES = len(ALPHABET)\n",
    "BATCH_SIZE  = 64\n",
    "EPOCHS      = 20\n",
    "LR          = 1e-3\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Transforms ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "val_tf = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Datasets & Loaders ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "train_ds = ImageFolder(\"TextBasedWave/chars_by_class/train\", transform=train_tf)\n",
    "val_ds   = ImageFolder(\"TextBasedWave/chars_by_class/val\",   transform=val_tf)\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=4)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Modelo CNN + LSTM ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "class CharCNN_LSTM(nn.Module):\n",
    "    def __init__(self, num_classes, lstm_hidden=256):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),              # 32‚Üí16\n",
    "            nn.Conv2d(64,128,3,padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2)               # 16‚Üí8\n",
    "        )\n",
    "        self.lstm = nn.LSTM(input_size=128*8,\n",
    "                            hidden_size=lstm_hidden,\n",
    "                            batch_first=True)\n",
    "        self.classifier = nn.Linear(lstm_hidden, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.cnn(x)              # [B,128,8,8]\n",
    "        B, C, H, W = feat.size()\n",
    "        seq = feat.permute(0,3,1,2).contiguous().view(B, W, C*H)\n",
    "        out, (hn, cn) = self.lstm(seq)  # [B, W, lstm_hidden]\n",
    "        last = out[:, -1, :]\n",
    "        return self.classifier(last)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Instancia√ß√£o ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "model     = CharCNN_LSTM(NUM_CLASSES).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Loop de Treino/Valida√ß√£o ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    running_loss, total, correct = 0, 0, 0\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(imgs)\n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        preds = out.argmax(1)\n",
    "        total   += labels.size(0)\n",
    "        correct += (preds == labels).sum().item()\n",
    "    train_acc = correct/total\n",
    "\n",
    "    model.eval()\n",
    "    v_total, v_correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "            out = model(imgs)\n",
    "            preds = out.argmax(1)\n",
    "            v_total   += labels.size(0)\n",
    "            v_correct += (preds == labels).sum().item()\n",
    "    val_acc = v_correct / v_total\n",
    "\n",
    "    print(f\"Ep {epoch:02d}  Loss={running_loss/len(train_loader):.3f}  \"\n",
    "          f\"TrainAcc={train_acc:.3f}  ValAcc={val_acc:.3f}\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Salvando o modelo ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "save_path = os.path.join(\"models\", \"charcnn_lstm.pt\")\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"Modelo salvo em: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f8172cd8-94fd-4a9e-a9df-6985e6f8311c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processamento de segmenta√ß√£o e padding conclu√≠do.\n"
     ]
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ‚îÄ Configura√ß√µes ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "VAL_DIR     = \"C:/Users/joao_/captcha/TextBasedWave/train\"          # Pasta com CAPTCHAs originais\n",
    "OUTPUT_DIR  = \"C:/Users/joao_/captcha/TextBasedWave/segments\"     # Pasta raiz onde cada imagem ter√° sua pr√≥pria pasta\n",
    "MIN_W, MIN_H = 5, 10                   # Tamanho m√≠nimo de cada segmento\n",
    "SPLIT_W     = 30                       # Largura acima da qual dividimos em dois\n",
    "TARGET_SIZE = 32                       # tamanho final com padding\n",
    "\n",
    "def get_character_boxes(img, min_w=MIN_W, min_h=MIN_H):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, bw = cv2.threshold(gray, 0, 255,\n",
    "                         cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "    opened = cv2.morphologyEx(bw, cv2.MORPH_OPEN, kernel)\n",
    "    cnts, _ = cv2.findContours(opened, cv2.RETR_EXTERNAL,\n",
    "                               cv2.CHAIN_APPROX_SIMPLE)\n",
    "    boxes = [\n",
    "        (x, y, w, h)\n",
    "        for c in cnts\n",
    "        for x, y, w, h in [cv2.boundingRect(c)]\n",
    "        if w >= min_w and h >= min_h\n",
    "    ]\n",
    "    return sorted(boxes, key=lambda b: b[0])\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Loop sobre cada CAPTCHA ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "for fname in sorted(os.listdir(VAL_DIR)):\n",
    "    name, ext = os.path.splitext(fname)\n",
    "    img_path = os.path.join(VAL_DIR, fname)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(f\"[ERRO] n√£o foi poss√≠vel ler {fname}\")\n",
    "        continue\n",
    "\n",
    "    boxes = get_character_boxes(img)\n",
    "    crops = []\n",
    "    for (x, y, w, h) in boxes:\n",
    "        if w > SPLIT_W:\n",
    "            mid = w // 2\n",
    "            crops.append(img[y:y+h, x    :x+mid])\n",
    "            crops.append(img[y:y+h, x+mid:x+w])\n",
    "        else:\n",
    "            crops.append(img[y:y+h, x:x+w])\n",
    "\n",
    "    # s√≥ continua se bate com o nome\n",
    "    if len(crops) != len(name):\n",
    "        # fallback: cortar horizontalmente em len(name) partes iguais\n",
    "        h, w = img.shape[:2]\n",
    "        part_w = w // len(name)\n",
    "        crops = [img[:, i*part_w:(i+1)*part_w] for i in range(len(name))]\n",
    "\n",
    "    out_folder = os.path.join(OUTPUT_DIR, name)\n",
    "    os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "    for idx, crop in enumerate(crops, start=1):\n",
    "        h, w = crop.shape[:2]\n",
    "\n",
    "        # 1) redimensiona se maior que TARGET_SIZE, mantendo propor√ß√£o\n",
    "        scale = min(1.0, TARGET_SIZE / h, TARGET_SIZE / w)\n",
    "        new_w, new_h = int(w * scale), int(h * scale)\n",
    "        if scale < 1.0:\n",
    "            crop = cv2.resize(crop, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "        else:\n",
    "            new_w, new_h = w, h\n",
    "\n",
    "        # 2) cria canvas branco 32√ó32\n",
    "        canvas = np.ones((TARGET_SIZE, TARGET_SIZE, 3), dtype=crop.dtype) * 255\n",
    "\n",
    "        # 3) centraliza\n",
    "        y_off = (TARGET_SIZE - new_h) // 2\n",
    "        x_off = (TARGET_SIZE - new_w) // 2\n",
    "        canvas[y_off:y_off+new_h, x_off:x_off+new_w] = crop\n",
    "\n",
    "        # 4) salva\n",
    "        out_path = os.path.join(out_folder, f\"{idx:02d}.png\")\n",
    "        cv2.imwrite(out_path, canvas)\n",
    "\n",
    "print(\"Processamento de segmenta√ß√£o e padding conclu√≠do.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602bd415-21d8-4d45-bd15-40019b9b625a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "# ‚îÄ‚îÄ Configura√ß√µes ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "BASE_FOLDER    = \"TextBasedWave/segments\"\n",
    "MODEL_PATH     = \"models/charcnn_lstm.pt\"\n",
    "DEVICE         = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "EXTENSIONS     = (\".png\", \".jpg\", \".jpeg\")\n",
    "\n",
    "# ‚îÄ‚îÄ Carrega modelo ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "model = CharCNN_LSTM(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "# ‚îÄ‚îÄ √çndice‚Üír√≥tulo ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "train_ds    = ImageFolder(\"TextBasedWave/chars_by_class/train\", transform=train_tf)\n",
    "class_names = train_ds.classes\n",
    "\n",
    "# ‚îÄ‚îÄ Transform de infer√™ncia ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "infer_tf = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "def prepare_img(gray_np):\n",
    "    return infer_tf(gray_np)\n",
    "\n",
    "# ‚îÄ‚îÄ Inicializa contadores ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "total_sequences        = 0\n",
    "correct_sequences      = 0\n",
    "overall_char_correct   = 0\n",
    "overall_char_total     = 0\n",
    "\n",
    "# ‚îÄ‚îÄ Loop em cada CAPTCHA (pasta) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "for label in sorted(os.listdir(BASE_FOLDER)):\n",
    "    folder = os.path.join(BASE_FOLDER, label)\n",
    "    if not os.path.isdir(folder):\n",
    "        continue\n",
    "\n",
    "    total_sequences += 1\n",
    "    seq_correct = 0\n",
    "    seq_total   = 0\n",
    "\n",
    "    # percorre os segmentos dessa pasta\n",
    "    for fname in sorted(os.listdir(folder)):\n",
    "        if not fname.lower().endswith(EXTENSIONS):\n",
    "            continue\n",
    "\n",
    "        # determina o caractere ‚Äúverdadeiro‚Äù pelo √≠ndice do arquivo\n",
    "        seg_idx   = int(os.path.splitext(fname)[0]) - 1\n",
    "        true_char = label[seg_idx]\n",
    "\n",
    "        # infer√™ncia\n",
    "        gray      = cv2.imread(os.path.join(folder, fname), cv2.IMREAD_GRAYSCALE)\n",
    "        inp       = prepare_img(gray).unsqueeze(0).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            out       = model(inp)\n",
    "            pred_char = class_names[out.argmax(dim=1).item()]\n",
    "\n",
    "        # atualiza contagens de segmento\n",
    "        is_corr = (pred_char == true_char)\n",
    "        seq_correct += is_corr\n",
    "        seq_total   += 1\n",
    "        overall_char_correct += is_corr\n",
    "        overall_char_total   += 1\n",
    "\n",
    "    # se todos os segmentos ficaram corretos, conta como sequ√™ncia certa\n",
    "    if seq_correct == seq_total and seq_total > 0:\n",
    "        correct_sequences += 1\n",
    "\n",
    "# ‚îÄ‚îÄ C√°lculo das m√©tricas ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "sequence_accuracy  = correct_sequences / total_sequences if total_sequences else 0\n",
    "character_accuracy = overall_char_correct / overall_char_total if overall_char_total else 0\n",
    "\n",
    "# ‚îÄ‚îÄ Impress√£o dos resultados ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "print(f\"Acur√°cia de sequ√™ncia (todas as letras corretas): \"\n",
    "      f\"{correct_sequences}/{total_sequences} = {sequence_accuracy:.2%}\")\n",
    "print(f\"Acur√°cia de caractere (individual): \"\n",
    "      f\"{overall_char_correct}/{overall_char_total} = {character_accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0ec6a0be-6968-408d-bef4-8979ecc72bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ Configura√ß√µes ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "BASE_FOLDER    = \"TextBasedWave/segments\"\n",
    "DATA_DIR       = \"TextBasedWave/chars_by_class\"              # seu diret√≥rio de treino\n",
    "PROJECT        = \"runs/captcha_wave_yolo\"\n",
    "EXP_NAME       = \"exp\"\n",
    "DEVICE         = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "EXTENSIONS     = (\".png\", \".jpg\", \".jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9417b103-b93f-485a-97de-c15e15a93e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolo11n-cls')\n",
    "model.train(\n",
    "    data=DATA_DIR,\n",
    "    epochs=50,\n",
    "    imgsz=32,\n",
    "    batch=64,\n",
    "    lrf=1e-3,\n",
    "    project=PROJECT,\n",
    "    name=EXP_NAME\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bec669-da08-4f68-a31d-5d650114a4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ 2) CARREGA O MODELO TREINADO ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "best_weight = os.path.join(PROJECT, EXP_NAME, \"weights\", \"best.pt\")\n",
    "\n",
    "model = YOLO(best_weight)\n",
    "\n",
    "class_names = [model.names[i] for i in sorted(model.names)]\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ Fun√ß√£o de predi√ß√£o para cada segmento ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "\n",
    "def predict_char(segment_path):\n",
    "    results = model.predict(\n",
    "        source=segment_path,\n",
    "        imgsz=32,\n",
    "        device=DEVICE,\n",
    "        verbose=False\n",
    "    )\n",
    "    # 1) acessa o tensor interno (torch.Tensor)\n",
    "    probs_tensor = results[0].probs.data  \n",
    "    # 2) move pra CPU e converte pra numpy de verdade\n",
    "    probs_array  = probs_tensor.cpu().numpy()  \n",
    "    # 3) pega o √≠ndice do valor m√°ximo\n",
    "    idx = int(probs_array.argmax())\n",
    "    # 4) retorna o nome da classe\n",
    "    return class_names[idx]\n",
    "\n",
    "# ‚îÄ‚îÄ 3) INFER√äNCIA & M√âTRICAS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "total_seq      = 0  # n√∫mero de pastas processadas\n",
    "correct_seq    = 0  # quantas tiveram todos os segmentos corretos\n",
    "total_chars    = 0  # total de segmentos\n",
    "correct_chars  = 0  # total de segmentos corretos\n",
    "\n",
    "for label in sorted(os.listdir(BASE_FOLDER)):\n",
    "    folder = os.path.join(BASE_FOLDER, label)\n",
    "    if not os.path.isdir(folder):\n",
    "        continue\n",
    "\n",
    "    total_seq += 1\n",
    "    seq_preds = []\n",
    "\n",
    "    # percorre cada arquivo de segmento\n",
    "    for fname in sorted(os.listdir(folder)):\n",
    "        if not fname.lower().endswith(EXTENSIONS):\n",
    "            continue\n",
    "\n",
    "        seg_idx   = int(os.path.splitext(fname)[0]) - 1\n",
    "        true_char = label[seg_idx]\n",
    "\n",
    "        path      = os.path.join(folder, fname)\n",
    "        pred_char = predict_char(path)\n",
    "\n",
    "        seq_preds.append((true_char, pred_char))\n",
    "        total_chars += 1\n",
    "        if pred_char == true_char:\n",
    "            correct_chars += 1\n",
    "\n",
    "    # se todos os pares (true,pred) baterem ‚Üí sequ√™ncia correta\n",
    "    if all(t == p for t, p in seq_preds) and seq_preds:\n",
    "        correct_seq += 1\n",
    "\n",
    "# ‚îÄ‚îÄ 4) RESULTADOS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "seq_acc  = correct_seq / total_seq    if total_seq  else 0\n",
    "char_acc = correct_chars / total_chars if total_chars else 0\n",
    "\n",
    "print(f\"Acur√°cia de sequ√™ncia (tudo certo): {correct_seq}/{total_seq} = {seq_acc:.2%}\")\n",
    "print(f\"Acur√°cia de caractere (isolado):   {correct_chars}/{total_chars} = {char_acc:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6125cdd-ffae-49c6-b400-fd1e470564a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# ‚îÄ‚îÄ 0) Defina DATA_DIR e carregue o dataset para descobrir num_classes ‚îÄ‚îÄ\n",
    "DATA_DIR = \"../TextBasedWave/chars_by_class\"\n",
    "train_tf = transforms.Compose([transforms.Resize((32,32)),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize([0.485,0.456,0.406],\n",
    "                                                    [0.229,0.224,0.225])])\n",
    "train_ds = datasets.ImageFolder(os.path.join(DATA_DIR, \"train\"), transform=train_tf)\n",
    "num_classes = len(train_ds.classes)  # ex: 36\n",
    "\n",
    "# ‚îÄ‚îÄ 1) Defini√ß√£o da classe sem usar valor padr√£o indefinido ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "class TemporalResNet50(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(TemporalResNet50, self).__init__()\n",
    "        base_model = models.resnet50()\n",
    "        self.backbone = nn.Sequential(*list(base_model.children())[:-2])\n",
    "        self.lstm     = nn.LSTM(input_size=2048, hidden_size=256,\n",
    "                                 num_layers=1, batch_first=True,\n",
    "                                 bidirectional=True)\n",
    "        self.classifier = nn.Linear(256 * 2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)          # [B, 2048, H, W]\n",
    "        b, c, h, w = x.size()\n",
    "        x = x.permute(0, 2, 3, 1).contiguous()  # [B, H, W, C]\n",
    "        x = x.view(b, h * w, c)                # [B, T, C]\n",
    "        x, _ = self.lstm(x)                    # [B, T, 512]\n",
    "        x = x[:, -1, :]                        # √∫ltimo timestep\n",
    "        return self.classifier(x)\n",
    "\n",
    "# ‚îÄ‚îÄ 2) Instancie o modelo passando num_classes ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TemporalResNet50(num_classes=num_classes).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c74837-e67a-402e-89a0-ebd346ee02c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ C√âLULA: TREINAMENTO DO TemporalResNet50 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ‚îÄ‚îÄ Configura√ß√µes ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "DATA_DIR      = \"TextBasedWave/chars_by_class\"                # estrutura: chars_by_class/train e chars_by_class/val\n",
    "PROJECT       = \"models/captcha_Wave_resnet50\"\n",
    "EXP_NAME      = \"exp\"\n",
    "DEVICE        = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "num_epochs    = 100\n",
    "batch_size    = 64\n",
    "learning_rate = 1e-3\n",
    "patience      = 15\n",
    "gamma         = 0.97    # para ExponentialLR\n",
    "\n",
    "# ‚îÄ‚îÄ Transforms ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "])\n",
    "val_tf   = transforms.Compose([\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "# ‚îÄ‚îÄ Datasets & DataLoaders ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "train_ds   = datasets.ImageFolder(os.path.join(DATA_DIR, \"train\"), transform=train_tf)\n",
    "val_ds     = datasets.ImageFolder(os.path.join(DATA_DIR, \"val\"),   transform=val_tf)\n",
    "trainloader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=4, pin_memory=True)\n",
    "testloader  = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# ‚îÄ‚îÄ Diret√≥rios de sa√≠da ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "weights_dir = os.path.join(PROJECT, EXP_NAME, \"weights\")\n",
    "os.makedirs(weights_dir, exist_ok=True)\n",
    "\n",
    "# ‚îÄ‚îÄ Modelo, Otimizador, Scheduler, Crit√©rio ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "model     = TemporalResNet50(num_classes=len(train_ds.classes)).to(DEVICE)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# ‚îÄ‚îÄ Loop de Treino com Early Stopping ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "best_val_acc     = 0.0\n",
    "epochs_no_improve = 0\n",
    "best_state_dict  = None\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    running_loss, running_corrects, running_total = 0.0, 0, 0\n",
    "    \n",
    "    for images, labels in tqdm(trainloader, desc=f\"[Epoch {epoch}] Treino\", leave=False):\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss     += loss.item() * images.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        running_corrects += (preds == labels).sum().item()\n",
    "        running_total    += labels.size(0)\n",
    "    \n",
    "    train_loss = running_loss / running_total\n",
    "    train_acc  = 100 * running_corrects / running_total\n",
    "    \n",
    "    # --- Valida√ß√£o ---\n",
    "    model.eval()\n",
    "    val_corrects, val_total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(testloader, desc=f\"[Epoch {epoch}] Valida√ß√£o\", leave=False):\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            val_corrects += (preds == labels).sum().item()\n",
    "            val_total    += labels.size(0)\n",
    "    \n",
    "    val_acc = 100 * val_corrects / val_total\n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch:2d} | \"\n",
    "          f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | \"\n",
    "          f\"Val Acc: {val_acc:.2f}%\")\n",
    "    \n",
    "    # Early Stopping\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc      = val_acc\n",
    "        epochs_no_improve = 0\n",
    "        best_state_dict   = model.state_dict()\n",
    "        torch.save(best_state_dict, os.path.join(weights_dir, \"best.pth\"))\n",
    "        print(f\"üìà Nova melhor Val Acc: {best_val_acc:.2f}% ‚Äî modelo salvo.\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"‚è∏Ô∏è Sem melhora por {epochs_no_improve} √©poca(s).\")\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"üõë Early stopping ativado ap√≥s {patience} √©pocas sem melhora.\")\n",
    "            break\n",
    "\n",
    "# ‚îÄ‚îÄ Restaurar melhor modelo ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "model.load_state_dict(best_state_dict)\n",
    "print(\"‚úîÔ∏è Treinamento conclu√≠do. Melhor modelo carregado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9191592-d759-4690-85d9-e9f9d86c544f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ C√âLULA: VALIDA√á√ÉO SEGMENTO-A-SEGMENTO COM TemporalResNet50 ‚îÄ‚îÄ\n",
    "\n",
    "# ‚îÄ‚îÄ 1) Configura√ß√µes ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "BASE_FOLDER    = \"TextBasedWave/segments\"               # pastas com r√≥tulos de sequ√™ncia\n",
    "EXTENSIONS     = (\".png\", \".jpg\", \".jpeg\")\n",
    "best_model_path = \"models/captcha_Wave_resnet50/exp/weights/best.pth\"         # ajuste para o seu caminho\n",
    "device         = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ‚îÄ‚îÄ 2) Carrega o modelo treinado ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "model = TemporalResNet50(num_classes=num_classes).to(device)\n",
    "model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# ‚îÄ‚îÄ 3) Transforms de valida√ß√£o (mesmo padr√£o do treino) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "val_tf = transforms.Compose([\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                         std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "# ‚îÄ‚îÄ 4) Fun√ß√£o de predi√ß√£o para um segmento ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def predict_char(segment_path):\n",
    "    img = Image.open(segment_path).convert(\"RGB\")\n",
    "    x   = val_tf(img).unsqueeze(0).to(device)            # [1,C,H,W]\n",
    "    with torch.no_grad():\n",
    "        logits = model(x)                                # [1,num_classes]\n",
    "        idx    = int(logits.argmax(dim=1).cpu().item())\n",
    "    return train_ds.classes[idx]                         # lista de classes do ImageFolder\n",
    "\n",
    "# ‚îÄ‚îÄ 5) Infer√™ncia & m√©tricas ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "total_seq     = 0   # total de sequ√™ncias (pastas)\n",
    "correct_seq   = 0   # quantas sequ√™ncias tiveram TODOS os chars corretos\n",
    "total_chars   = 0   # total de segmentos avaliados\n",
    "correct_chars = 0   # total de segmentos corretos\n",
    "\n",
    "for label in sorted(os.listdir(BASE_FOLDER)):\n",
    "    folder = os.path.join(BASE_FOLDER, label)\n",
    "    if not os.path.isdir(folder):\n",
    "        continue\n",
    "\n",
    "    total_seq += 1\n",
    "    seq_preds = []\n",
    "\n",
    "    for fname in sorted(os.listdir(folder)):\n",
    "        if not fname.lower().endswith(EXTENSIONS):\n",
    "            continue\n",
    "\n",
    "        seg_idx    = int(os.path.splitext(fname)[0]) - 1\n",
    "        true_char  = label[seg_idx]\n",
    "        path       = os.path.join(folder, fname)\n",
    "        pred_char  = predict_char(path)\n",
    "\n",
    "        seq_preds.append((true_char, pred_char))\n",
    "        total_chars += 1\n",
    "        if pred_char == true_char:\n",
    "            correct_chars += 1\n",
    "\n",
    "    if seq_preds and all(t == p for t, p in seq_preds):\n",
    "        correct_seq += 1\n",
    "\n",
    "# ‚îÄ‚îÄ 6) Resultados ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "seq_acc  = correct_seq   / total_seq   if total_seq   else 0\n",
    "char_acc = correct_chars / total_chars if total_chars else 0\n",
    "\n",
    "print(f\"Acur√°cia de sequ√™ncia (tudo certo): {correct_seq}/{total_seq} = {seq_acc:.2%}\")\n",
    "print(f\"Acur√°cia de caractere (isolado):   {correct_chars}/{total_chars} = {char_acc:.2%}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
