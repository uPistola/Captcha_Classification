{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89205333-6a74-4768-bf66-b3035bdc02f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0d124798-5543-4703-a5fb-7b2892a1a46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentação concluída! Pastas:\n",
      "  TextBasedWave/chars_by_class\\train\n",
      "  TextBasedWave/chars_by_class\\val\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_character_boxes(img, min_width=5, min_height=10):\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, bw = cv2.threshold(gray, 0, 255,\n",
    "                         cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "    opened = cv2.morphologyEx(bw, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    contours, _ = cv2.findContours(opened, cv2.RETR_EXTERNAL,\n",
    "                                   cv2.CHAIN_APPROX_SIMPLE)\n",
    "    boxes = []\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if w >= min_width and h >= min_height:\n",
    "            boxes.append((x, y, w, h))\n",
    "    return sorted(boxes, key=lambda b: b[0])\n",
    "\n",
    "\n",
    "def get_fixed_boxes(img, num_chars, min_width=5, min_height=10):\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "    slice_w = w // num_chars\n",
    "    boxes = []\n",
    "    for i in range(num_chars):\n",
    "        x1 = i * slice_w\n",
    "        x2 = w if i == num_chars - 1 else (i + 1) * slice_w\n",
    "        w_box = x2 - x1\n",
    "        if w_box >= min_width and h >= min_height:\n",
    "            boxes.append((x1, 0, w_box, h))\n",
    "    return boxes\n",
    "\n",
    "\n",
    "def normalize_and_pad(crop, size=32, border_color=(255,255,255)):\n",
    "\n",
    "    h0, w0 = crop.shape[:2]\n",
    "    # escala para caber em size\n",
    "    scale = min(size / h0, size / w0)\n",
    "    new_w, new_h = int(w0 * scale), int(h0 * scale)\n",
    "    # evita zero\n",
    "    new_w = max(1, new_w)\n",
    "    new_h = max(1, new_h)\n",
    "    resized = cv2.resize(crop, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "    # calcula padding\n",
    "    delta_w = size - new_w\n",
    "    delta_h = size - new_h\n",
    "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
    "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
    "    padded = cv2.copyMakeBorder(resized, top, bottom, left, right,\n",
    "                                cv2.BORDER_CONSTANT, value=list(border_color))\n",
    "    return padded\n",
    "\n",
    "\n",
    "def segment_and_save_split(csv_path, img_dir, output_base_dir,\n",
    "                           train_ratio=0.8, max_width=25, seed=42):\n",
    "\n",
    "    random.seed(42)\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Cria pastas para splits e classes\n",
    "    classes = sorted({c for lbl in df['label'].astype(str) for c in lbl})\n",
    "    for split in ('train', 'val'):\n",
    "        for char in classes:\n",
    "            os.makedirs(os.path.join(output_base_dir, split, char), exist_ok=True)\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        fname = row['filename']\n",
    "        label = str(row['label'])\n",
    "        img_path = os.path.join(img_dir, fname)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"Aviso: não encontrei {img_path}\")\n",
    "            continue\n",
    "\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "        # Escolhe split\n",
    "        split = 'train' if random.random() < train_ratio else 'val'\n",
    "\n",
    "        # Tenta segmentação por contornos\n",
    "        boxes = get_character_boxes(img)\n",
    "        # Se não bate com o número de caracteres, usa divisão fixa\n",
    "        if len(boxes) != len(label):\n",
    "            boxes = get_fixed_boxes(img, len(label))\n",
    "\n",
    "        # Salva crops filtrando largura máxima e padronizando tamanho\n",
    "        for i, ((x, y, w, h), char) in enumerate(zip(boxes, label)):\n",
    "            crop = img_gray[y:y+h, x:x+w]\n",
    "            norm_crop = normalize_and_pad(crop, size=32, border_color=(255,255,255))\n",
    "            char_dir = os.path.join(output_base_dir, split, char)\n",
    "            base, _ = os.path.splitext(fname)\n",
    "            out_name = f\"{base}_{i:02d}.png\"\n",
    "            cv2.imwrite(os.path.join(char_dir, out_name), norm_crop)\n",
    "\n",
    "    print(f\"Segmentação concluída! Pastas:\")\n",
    "    print(f\"  {os.path.join(output_base_dir, 'train')}\")\n",
    "    print(f\"  {os.path.join(output_base_dir, 'val')}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    CSV_PATH = 'TextBasedWave/train.csv'\n",
    "    IMG_DIR  = 'TextBasedWave/train'\n",
    "    OUT_DIR  = 'TextBasedWave/chars_by_class'\n",
    "    segment_and_save_split(CSV_PATH, IMG_DIR, OUT_DIR,\n",
    "                           train_ratio=0.8, max_width=25, seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28273e77-d840-4465-b239-f1eee3114877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 01  Loss=3.036  TrainAcc=0.179  ValAcc=0.354\n",
      "Ep 02  Loss=2.171  TrainAcc=0.455  ValAcc=0.498\n",
      "Ep 03  Loss=1.909  TrainAcc=0.539  ValAcc=0.537\n",
      "Ep 04  Loss=1.775  TrainAcc=0.571  ValAcc=0.549\n",
      "Ep 05  Loss=1.683  TrainAcc=0.591  ValAcc=0.554\n",
      "Ep 06  Loss=1.601  TrainAcc=0.606  ValAcc=0.558\n",
      "Ep 07  Loss=1.519  TrainAcc=0.623  ValAcc=0.558\n",
      "Ep 08  Loss=1.453  TrainAcc=0.638  ValAcc=0.567\n",
      "Ep 09  Loss=1.374  TrainAcc=0.650  ValAcc=0.563\n",
      "Ep 10  Loss=1.301  TrainAcc=0.666  ValAcc=0.565\n",
      "Ep 11  Loss=1.224  TrainAcc=0.683  ValAcc=0.564\n",
      "Ep 12  Loss=1.149  TrainAcc=0.699  ValAcc=0.567\n",
      "Ep 13  Loss=1.077  TrainAcc=0.713  ValAcc=0.564\n",
      "Ep 14  Loss=1.009  TrainAcc=0.730  ValAcc=0.558\n",
      "Ep 15  Loss=0.930  TrainAcc=0.751  ValAcc=0.562\n",
      "Ep 16  Loss=0.862  TrainAcc=0.770  ValAcc=0.555\n",
      "Ep 17  Loss=0.803  TrainAcc=0.785  ValAcc=0.548\n",
      "Ep 18  Loss=0.819  TrainAcc=0.777  ValAcc=0.553\n",
      "Ep 19  Loss=0.708  TrainAcc=0.809  ValAcc=0.546\n",
      "Ep 20  Loss=0.648  TrainAcc=0.830  ValAcc=0.546\n",
      "Modelo salvo em: models\\charcnn_lstm.pt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ─── Configurações ──────────────────────────────────────────────\n",
    "DEVICE      = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ALPHABET    = \"abcdefghijklmnopqrstuvwxyz0123456789\"\n",
    "NUM_CLASSES = len(ALPHABET)\n",
    "BATCH_SIZE  = 64\n",
    "EPOCHS      = 20\n",
    "LR          = 1e-3\n",
    "\n",
    "# ─── Transforms ─────────────────────────────────────────────────\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "val_tf = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# ─── Datasets & Loaders ────────────────────────────────────────\n",
    "train_ds = ImageFolder(\"TextBased/chars_by_class/train\", transform=train_tf)\n",
    "val_ds   = ImageFolder(\"TextBased/chars_by_class/val\",   transform=val_tf)\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=4)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "# ─── Modelo CNN + LSTM ─────────────────────────────────────────\n",
    "class CharCNN_LSTM(nn.Module):\n",
    "    def __init__(self, num_classes, lstm_hidden=256):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),              # 32→16\n",
    "            nn.Conv2d(64,128,3,padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2)               # 16→8\n",
    "        )\n",
    "        self.lstm = nn.LSTM(input_size=128*8,\n",
    "                            hidden_size=lstm_hidden,\n",
    "                            batch_first=True)\n",
    "        self.classifier = nn.Linear(lstm_hidden, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.cnn(x)              # [B,128,8,8]\n",
    "        B, C, H, W = feat.size()\n",
    "        seq = feat.permute(0,3,1,2).contiguous().view(B, W, C*H)\n",
    "        out, (hn, cn) = self.lstm(seq)  # [B, W, lstm_hidden]\n",
    "        last = out[:, -1, :]\n",
    "        return self.classifier(last)\n",
    "\n",
    "# ─── Instanciação ──────────────────────────────────────────────\n",
    "model     = CharCNN_LSTM(NUM_CLASSES).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# ─── Loop de Treino/Validação ──────────────────────────────────\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    running_loss, total, correct = 0, 0, 0\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(imgs)\n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        preds = out.argmax(1)\n",
    "        total   += labels.size(0)\n",
    "        correct += (preds == labels).sum().item()\n",
    "    train_acc = correct/total\n",
    "\n",
    "    model.eval()\n",
    "    v_total, v_correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "            out = model(imgs)\n",
    "            preds = out.argmax(1)\n",
    "            v_total   += labels.size(0)\n",
    "            v_correct += (preds == labels).sum().item()\n",
    "    val_acc = v_correct / v_total\n",
    "\n",
    "    print(f\"Ep {epoch:02d}  Loss={running_loss/len(train_loader):.3f}  \"\n",
    "          f\"TrainAcc={train_acc:.3f}  ValAcc={val_acc:.3f}\")\n",
    "\n",
    "# ─── Salvando o modelo ─────────────────────────────────────────\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "save_path = os.path.join(\"models\", \"charcnn_lstm.pt\")\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"Modelo salvo em: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a7e9345-a938-4566-8fc1-60069863b790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processamento de segmentação e padding concluído.\n"
     ]
    }
   ],
   "source": [
    "# ─── Configurações ──────────────────────────────────────────────\n",
    "VAL_DIR     = \"TextBased/val\"          # Pasta com CAPTCHAs originais\n",
    "OUTPUT_DIR  = \"TextBased/segments\"     # Pasta raiz onde cada imagem terá sua própria pasta\n",
    "MIN_W, MIN_H = 5, 10                   # Tamanho mínimo de cada segmento\n",
    "SPLIT_W     = 30                       # Largura acima da qual dividimos em dois\n",
    "TARGET_SIZE = 32                       # tamanho final com padding\n",
    "\n",
    "def get_character_boxes(img, min_w=MIN_W, min_h=MIN_H):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, bw = cv2.threshold(gray, 0, 255,\n",
    "                         cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "    opened = cv2.morphologyEx(bw, cv2.MORPH_OPEN, kernel)\n",
    "    cnts, _ = cv2.findContours(opened, cv2.RETR_EXTERNAL,\n",
    "                               cv2.CHAIN_APPROX_SIMPLE)\n",
    "    boxes = [\n",
    "        (x, y, w, h)\n",
    "        for c in cnts\n",
    "        for x, y, w, h in [cv2.boundingRect(c)]\n",
    "        if w >= min_w and h >= min_h\n",
    "    ]\n",
    "    return sorted(boxes, key=lambda b: b[0])\n",
    "\n",
    "# ─── Loop sobre cada CAPTCHA ────────────────────────────────────\n",
    "for fname in sorted(os.listdir(VAL_DIR)):\n",
    "    name, ext = os.path.splitext(fname)\n",
    "    img_path = os.path.join(VAL_DIR, fname)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(f\"[ERRO] não foi possível ler {fname}\")\n",
    "        continue\n",
    "\n",
    "    boxes = get_character_boxes(img)\n",
    "    crops = []\n",
    "    for (x, y, w, h) in boxes:\n",
    "        if w > SPLIT_W:\n",
    "            mid = w // 2\n",
    "            crops.append(img[y:y+h, x    :x+mid])\n",
    "            crops.append(img[y:y+h, x+mid:x+w])\n",
    "        else:\n",
    "            crops.append(img[y:y+h, x:x+w])\n",
    "\n",
    "    # só continua se bate com o nome\n",
    "    if len(crops) != len(name):\n",
    "        continue\n",
    "\n",
    "    out_folder = os.path.join(OUTPUT_DIR, name)\n",
    "    os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "    for idx, crop in enumerate(crops, start=1):\n",
    "        h, w = crop.shape[:2]\n",
    "\n",
    "        # 1) redimensiona se maior que TARGET_SIZE, mantendo proporção\n",
    "        scale = min(1.0, TARGET_SIZE / h, TARGET_SIZE / w)\n",
    "        new_w, new_h = int(w * scale), int(h * scale)\n",
    "        if scale < 1.0:\n",
    "            crop = cv2.resize(crop, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "        else:\n",
    "            new_w, new_h = w, h\n",
    "\n",
    "        # 2) cria canvas branco 32×32\n",
    "        canvas = np.ones((TARGET_SIZE, TARGET_SIZE, 3), dtype=crop.dtype) * 255\n",
    "\n",
    "        # 3) centraliza\n",
    "        y_off = (TARGET_SIZE - new_h) // 2\n",
    "        x_off = (TARGET_SIZE - new_w) // 2\n",
    "        canvas[y_off:y_off+new_h, x_off:x_off+new_w] = crop\n",
    "\n",
    "        # 4) salva\n",
    "        out_path = os.path.join(out_folder, f\"{idx:02d}.png\")\n",
    "        cv2.imwrite(out_path, canvas)\n",
    "\n",
    "print(\"Processamento de segmentação e padding concluído.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1eca366-6d53-4e99-abbd-56db44a16240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia de sequência (todas as letras corretas): 3076/3745 = 82.14%\n",
      "Acurácia de caractere (individual): 17928/18725 = 95.74%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "# ── Configurações ────────────────────────────────────────────────\n",
    "BASE_FOLDER    = \"TextBased/segments\"\n",
    "MODEL_PATH     = \"models/charcnn_lstm.pt\"\n",
    "DEVICE         = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "EXTENSIONS     = (\".png\", \".jpg\", \".jpeg\")\n",
    "\n",
    "# ── Carrega modelo ───────────────────────────────────────────────\n",
    "model = CharCNN_LSTM(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "# ── Índice→rótulo ────────────────────────────────────────────────\n",
    "train_ds    = ImageFolder(\"TextBased/chars_by_class/train\", transform=train_tf)\n",
    "class_names = train_ds.classes\n",
    "\n",
    "# ── Transform de inferência ───────────────────────────────────────\n",
    "infer_tf = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "def prepare_img(gray_np):\n",
    "    return infer_tf(gray_np)\n",
    "\n",
    "# ── Inicializa contadores ────────────────────────────────────────\n",
    "total_sequences        = 0\n",
    "correct_sequences      = 0\n",
    "overall_char_correct   = 0\n",
    "overall_char_total     = 0\n",
    "\n",
    "# ── Loop em cada CAPTCHA (pasta) ────────────────────────────────\n",
    "for label in sorted(os.listdir(BASE_FOLDER)):\n",
    "    folder = os.path.join(BASE_FOLDER, label)\n",
    "    if not os.path.isdir(folder):\n",
    "        continue\n",
    "\n",
    "    total_sequences += 1\n",
    "    seq_correct = 0\n",
    "    seq_total   = 0\n",
    "\n",
    "    # percorre os segmentos dessa pasta\n",
    "    for fname in sorted(os.listdir(folder)):\n",
    "        if not fname.lower().endswith(EXTENSIONS):\n",
    "            continue\n",
    "\n",
    "        # determina o caractere “verdadeiro” pelo índice do arquivo\n",
    "        seg_idx   = int(os.path.splitext(fname)[0]) - 1\n",
    "        true_char = label[seg_idx]\n",
    "\n",
    "        # inferência\n",
    "        gray      = cv2.imread(os.path.join(folder, fname), cv2.IMREAD_GRAYSCALE)\n",
    "        inp       = prepare_img(gray).unsqueeze(0).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            out       = model(inp)\n",
    "            pred_char = class_names[out.argmax(dim=1).item()]\n",
    "\n",
    "        # atualiza contagens de segmento\n",
    "        is_corr = (pred_char == true_char)\n",
    "        seq_correct += is_corr\n",
    "        seq_total   += 1\n",
    "        overall_char_correct += is_corr\n",
    "        overall_char_total   += 1\n",
    "\n",
    "    # se todos os segmentos ficaram corretos, conta como sequência certa\n",
    "    if seq_correct == seq_total and seq_total > 0:\n",
    "        correct_sequences += 1\n",
    "\n",
    "# ── Cálculo das métricas ────────────────────────────────────────\n",
    "sequence_accuracy  = correct_sequences / total_sequences if total_sequences else 0\n",
    "character_accuracy = overall_char_correct / overall_char_total if overall_char_total else 0\n",
    "\n",
    "# ── Impressão dos resultados ────────────────────────────────────\n",
    "print(f\"Acurácia de sequência (todas as letras corretas): \"\n",
    "      f\"{correct_sequences}/{total_sequences} = {sequence_accuracy:.2%}\")\n",
    "print(f\"Acurácia de caractere (individual): \"\n",
    "      f\"{overall_char_correct}/{overall_char_total} = {character_accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb01663-1cd8-4f16-bd61-ff7bfc5e4700",
   "metadata": {},
   "source": [
    "# Treinamento YOLO segmentação + classificação de caracteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32aa8784-918c-40c2-8947-dfcb74f1cfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Configurações ────────────────────────────────────────────────\n",
    "BASE_FOLDER    = \"C:/Users/joao_/captcha/TextBased/segments\"\n",
    "DATA_DIR       = \"../TextBased/chars_by_class\"              # seu diretório de treino\n",
    "PROJECT        = \"../runs/captcha_yolo\"\n",
    "EXP_NAME       = \"exp\"\n",
    "DEVICE         = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "EXTENSIONS     = (\".png\", \".jpg\", \".jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b7e02f-926f-4e0c-8053-854aea44a088",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolo11n-cls')\n",
    "\n",
    "model.train(\n",
    "    data=DATA_DIR,\n",
    "    epochs=50,\n",
    "    imgsz=32,\n",
    "    batch=64,\n",
    "    lrf=1e-3,\n",
    "    project=PROJECT,\n",
    "    name=EXP_NAME\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb4714b1-e7f9-4381-aa68-e3bd6793cfb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia de sequência (tudo certo): 3175/3745 = 84.78%\n",
      "Acurácia de caractere (isolado):   18071/18725 = 96.51%\n"
     ]
    }
   ],
   "source": [
    "# ── 2) CARREGA O MODELO TREINADO ────────────────────────────────\n",
    "best_weight = os.path.join(PROJECT, EXP_NAME, \"weights\", \"best.pt\")\n",
    "\n",
    "model = YOLO(best_weight)\n",
    "\n",
    "class_names = [model.names[i] for i in sorted(model.names)]\n",
    "\n",
    "\n",
    "# ── Função de predição para cada segmento ──────────────────────\n",
    "\n",
    "\n",
    "def predict_char(segment_path):\n",
    "    results = model.predict(\n",
    "        source=segment_path,\n",
    "        imgsz=32,\n",
    "        device=DEVICE,\n",
    "        verbose=False\n",
    "    )\n",
    "    # 1) acessa o tensor interno (torch.Tensor)\n",
    "    probs_tensor = results[0].probs.data  \n",
    "    # 2) move pra CPU e converte pra numpy de verdade\n",
    "    probs_array  = probs_tensor.cpu().numpy()  \n",
    "    # 3) pega o índice do valor máximo\n",
    "    idx = int(probs_array.argmax())\n",
    "    # 4) retorna o nome da classe\n",
    "    return class_names[idx]\n",
    "\n",
    "# ── 3) INFERÊNCIA & MÉTRICAS ────────────────────────────────────\n",
    "total_seq      = 0  # número de pastas processadas\n",
    "correct_seq    = 0  # quantas tiveram todos os segmentos corretos\n",
    "total_chars    = 0  # total de segmentos\n",
    "correct_chars  = 0  # total de segmentos corretos\n",
    "\n",
    "for label in sorted(os.listdir(BASE_FOLDER)):\n",
    "    folder = os.path.join(BASE_FOLDER, label)\n",
    "    if not os.path.isdir(folder):\n",
    "        continue\n",
    "\n",
    "    total_seq += 1\n",
    "    seq_preds = []\n",
    "\n",
    "    # percorre cada arquivo de segmento\n",
    "    for fname in sorted(os.listdir(folder)):\n",
    "        if not fname.lower().endswith(EXTENSIONS):\n",
    "            continue\n",
    "\n",
    "        seg_idx   = int(os.path.splitext(fname)[0]) - 1\n",
    "        true_char = label[seg_idx]\n",
    "\n",
    "        path      = os.path.join(folder, fname)\n",
    "        pred_char = predict_char(path)\n",
    "\n",
    "        seq_preds.append((true_char, pred_char))\n",
    "        total_chars += 1\n",
    "        if pred_char == true_char:\n",
    "            correct_chars += 1\n",
    "\n",
    "    # se todos os pares (true,pred) baterem → sequência correta\n",
    "    if all(t == p for t, p in seq_preds) and seq_preds:\n",
    "        correct_seq += 1\n",
    "\n",
    "# ── 4) RESULTADOS ───────────────────────────────────────────────\n",
    "seq_acc  = correct_seq / total_seq    if total_seq  else 0\n",
    "char_acc = correct_chars / total_chars if total_chars else 0\n",
    "\n",
    "print(f\"Acurácia de sequência (tudo certo): {correct_seq}/{total_seq} = {seq_acc:.2%}\")\n",
    "print(f\"Acurácia de caractere (isolado):   {correct_chars}/{total_chars} = {char_acc:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1306de8-7b05-4b47-a345-d004fab7f0b5",
   "metadata": {},
   "source": [
    "# Treinamento com ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d929e963-7aae-4525-853d-66d45ad9b208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# ── 0) Defina DATA_DIR e carregue o dataset para descobrir num_classes ──\n",
    "DATA_DIR = \"C:/Users/joao_/captcha/TextBased/chars_by_class\"\n",
    "train_tf = transforms.Compose([transforms.Resize((64,64)),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize([0.485,0.456,0.406],\n",
    "                                                    [0.229,0.224,0.225])])\n",
    "train_ds = datasets.ImageFolder(os.path.join(DATA_DIR, \"train\"), transform=train_tf)\n",
    "num_classes = len(train_ds.classes)  # ex: 36\n",
    "\n",
    "# ── 1) Definição da classe sem usar valor padrão indefinido ───────────\n",
    "class TemporalResNet50(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(TemporalResNet50, self).__init__()\n",
    "        base_model = models.resnet50()\n",
    "        self.backbone = nn.Sequential(*list(base_model.children())[:-2])\n",
    "        self.lstm     = nn.LSTM(input_size=2048, hidden_size=256,\n",
    "                                 num_layers=1, batch_first=True,\n",
    "                                 bidirectional=True)\n",
    "        self.classifier = nn.Linear(256 * 2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)          # [B, 2048, H, W]\n",
    "        b, c, h, w = x.size()\n",
    "        x = x.permute(0, 2, 3, 1).contiguous()  # [B, H, W, C]\n",
    "        x = x.view(b, h * w, c)                # [B, T, C]\n",
    "        x, _ = self.lstm(x)                    # [B, T, 512]\n",
    "        x = x[:, -1, :]                        # último timestep\n",
    "        return self.classifier(x)\n",
    "\n",
    "# ── 2) Instancie o modelo passando num_classes ────────────────────────\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TemporalResNet50(num_classes=num_classes).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2f9255-c7aa-487b-bfbc-480271dd73c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── CÉLULA: TREINAMENTO DO TemporalResNet50 ────────────────────────\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ── Configurações ─────────────────────────────────────────────────\n",
    "DATA_DIR      = \"C:/Users/joao_/captcha/TextBased/chars_by_class\"                # estrutura: chars_by_class/train e chars_by_class/val\n",
    "PROJECT       = \"models/captcha_resnet50\"\n",
    "EXP_NAME      = \"exp\"\n",
    "DEVICE        = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "num_epochs    = 50\n",
    "batch_size    = 64\n",
    "learning_rate = 1e-3\n",
    "patience      = 15\n",
    "gamma         = 0.97    # para ExponentialLR\n",
    "\n",
    "# ── Transforms ────────────────────────────────────────────────────\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "])\n",
    "val_tf   = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "# ── Datasets & DataLoaders ────────────────────────────────────────\n",
    "train_ds   = datasets.ImageFolder(os.path.join(DATA_DIR, \"train\"), transform=train_tf)\n",
    "val_ds     = datasets.ImageFolder(os.path.join(DATA_DIR, \"val\"),   transform=val_tf)\n",
    "trainloader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=4, pin_memory=True)\n",
    "testloader  = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# ── Diretórios de saída ───────────────────────────────────────────\n",
    "weights_dir = os.path.join(PROJECT, EXP_NAME, \"weights\")\n",
    "os.makedirs(weights_dir, exist_ok=True)\n",
    "\n",
    "# ── Modelo, Otimizador, Scheduler, Critério ────────────────────────\n",
    "model     = TemporalResNet50(num_classes=len(train_ds.classes)).to(DEVICE)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# ── Loop de Treino com Early Stopping ──────────────────────────────\n",
    "best_val_acc     = 0.0\n",
    "epochs_no_improve = 0\n",
    "best_state_dict  = None\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    running_loss, running_corrects, running_total = 0.0, 0, 0\n",
    "    \n",
    "    for images, labels in tqdm(trainloader, desc=f\"[Epoch {epoch}] Treino\", leave=False):\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss     += loss.item() * images.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        running_corrects += (preds == labels).sum().item()\n",
    "        running_total    += labels.size(0)\n",
    "    \n",
    "    train_loss = running_loss / running_total\n",
    "    train_acc  = 100 * running_corrects / running_total\n",
    "    \n",
    "    # --- Validação ---\n",
    "    model.eval()\n",
    "    val_corrects, val_total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(testloader, desc=f\"[Epoch {epoch}] Validação\", leave=False):\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            val_corrects += (preds == labels).sum().item()\n",
    "            val_total    += labels.size(0)\n",
    "    \n",
    "    val_acc = 100 * val_corrects / val_total\n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch:2d} | \"\n",
    "          f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | \"\n",
    "          f\"Val Acc: {val_acc:.2f}%\")\n",
    "    \n",
    "    # Early Stopping\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc      = val_acc\n",
    "        epochs_no_improve = 0\n",
    "        best_state_dict   = model.state_dict()\n",
    "        torch.save(best_state_dict, os.path.join(weights_dir, \"best.pth\"))\n",
    "        print(f\"📈 Nova melhor Val Acc: {best_val_acc:.2f}% — modelo salvo.\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"⏸️ Sem melhora por {epochs_no_improve} época(s).\")\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"🛑 Early stopping ativado após {patience} épocas sem melhora.\")\n",
    "            break\n",
    "\n",
    "# ── Restaurar melhor modelo ───────────────────────────────────────\n",
    "model.load_state_dict(best_state_dict)\n",
    "print(\"✔️ Treinamento concluído. Melhor modelo carregado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b9e19de-19e5-41e6-addc-0fe1a931108e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia de sequência (tudo certo): 2409/3745 = 64.33%\n",
      "Acurácia de caractere (isolado):   16952/18725 = 90.53%\n"
     ]
    }
   ],
   "source": [
    "# ── CÉLULA: VALIDAÇÃO SEGMENTO-A-SEGMENTO COM TemporalResNet50 ──\n",
    "\n",
    "# ── 1) Configurações ─────────────────────────────────────────────\n",
    "BASE_FOLDER    = \"TextBased/segments\"               # pastas com rótulos de sequência\n",
    "EXTENSIONS     = (\".png\", \".jpg\", \".jpeg\")\n",
    "best_model_path = \"models/ResNet_TextBase.pth\"         # ajuste para o seu caminho\n",
    "device         = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ── 2) Carrega o modelo treinado ─────────────────────────────────\n",
    "model = TemporalResNet50(num_classes=num_classes).to(device)\n",
    "model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# ── 3) Transforms de validação (mesmo padrão do treino) ──────────\n",
    "val_tf = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                         std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "# ── 4) Função de predição para um segmento ───────────────────────\n",
    "def predict_char(segment_path):\n",
    "    img = Image.open(segment_path).convert(\"RGB\")\n",
    "    x   = val_tf(img).unsqueeze(0).to(device)            # [1,C,H,W]\n",
    "    with torch.no_grad():\n",
    "        logits = model(x)                                # [1,num_classes]\n",
    "        idx    = int(logits.argmax(dim=1).cpu().item())\n",
    "    return train_ds.classes[idx]                         # lista de classes do ImageFolder\n",
    "\n",
    "# ── 5) Inferência & métricas ────────────────────────────────────\n",
    "total_seq     = 0   # total de sequências (pastas)\n",
    "correct_seq   = 0   # quantas sequências tiveram TODOS os chars corretos\n",
    "total_chars   = 0   # total de segmentos avaliados\n",
    "correct_chars = 0   # total de segmentos corretos\n",
    "\n",
    "for label in sorted(os.listdir(BASE_FOLDER)):\n",
    "    folder = os.path.join(BASE_FOLDER, label)\n",
    "    if not os.path.isdir(folder):\n",
    "        continue\n",
    "\n",
    "    total_seq += 1\n",
    "    seq_preds = []\n",
    "\n",
    "    for fname in sorted(os.listdir(folder)):\n",
    "        if not fname.lower().endswith(EXTENSIONS):\n",
    "            continue\n",
    "\n",
    "        seg_idx    = int(os.path.splitext(fname)[0]) - 1\n",
    "        true_char  = label[seg_idx]\n",
    "        path       = os.path.join(folder, fname)\n",
    "        pred_char  = predict_char(path)\n",
    "\n",
    "        seq_preds.append((true_char, pred_char))\n",
    "        total_chars += 1\n",
    "        if pred_char == true_char:\n",
    "            correct_chars += 1\n",
    "\n",
    "    if seq_preds and all(t == p for t, p in seq_preds):\n",
    "        correct_seq += 1\n",
    "\n",
    "# ── 6) Resultados ────────────────────────────────────────────────\n",
    "seq_acc  = correct_seq   / total_seq   if total_seq   else 0\n",
    "char_acc = correct_chars / total_chars if total_chars else 0\n",
    "\n",
    "print(f\"Acurácia de sequência (tudo certo): {correct_seq}/{total_seq} = {seq_acc:.2%}\")\n",
    "print(f\"Acurácia de caractere (isolado):   {correct_chars}/{total_chars} = {char_acc:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a69e6af-85be-40f4-9bb7-10d60e52a693",
   "metadata": {},
   "source": [
    "# Teste com Dataset com Wave Distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "819d5740-1393-4ebb-86fd-665e0bb1f0c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] O sistema não pode encontrar o caminho especificado: 'C:/Users/joao_/captcha/TextBasedWave/chars_by_class'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m random\u001b[38;5;241m.\u001b[39mseed(RANDOM_SEED)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Coletar todas as imagens por classe\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m class_dirs \u001b[38;5;241m=\u001b[39m [d \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBASE_DIR\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(BASE_DIR, d)) \u001b[38;5;129;01mand\u001b[39;00m d \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m SPLITS]\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Preparar estrutura de pastas\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m SPLITS:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] O sistema não pode encontrar o caminho especificado: 'C:/Users/joao_/captcha/TextBasedWave/chars_by_class'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "\n",
    "# Parâmetros\n",
    "BASE_DIR      = \"C:/Users/joao_/captcha/TextBasedWave/chars_by_class\"\n",
    "SPLITS        = ['train', 'val']\n",
    "TRAIN_RATIO   = 0.8\n",
    "RANDOM_SEED   = 42\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "# Coletar todas as imagens por classe\n",
    "class_dirs = [d for d in os.listdir(BASE_DIR) if os.path.isdir(os.path.join(BASE_DIR, d)) and d not in SPLITS]\n",
    "\n",
    "# Preparar estrutura de pastas\n",
    "for split in SPLITS:\n",
    "    for cls in class_dirs:\n",
    "        os.makedirs(os.path.join(BASE_DIR, split, cls), exist_ok=True)\n",
    "\n",
    "# Divisão train/val\n",
    "for cls in class_dirs:\n",
    "    cls_dir = os.path.join(BASE_DIR, cls)\n",
    "    images  = [f for f in os.listdir(cls_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    random.shuffle(images)\n",
    "\n",
    "    split_idx = int(len(images) * TRAIN_RATIO)\n",
    "    train_imgs = images[:split_idx]\n",
    "    val_imgs   = images[split_idx:]\n",
    "\n",
    "    for fname in train_imgs:\n",
    "        src = os.path.join(cls_dir, fname)\n",
    "        dst = os.path.join(BASE_DIR, 'train', cls, fname)\n",
    "        shutil.move(src, dst)\n",
    "\n",
    "    for fname in val_imgs:\n",
    "        src = os.path.join(cls_dir, fname)\n",
    "        dst = os.path.join(BASE_DIR, 'val', cls, fname)\n",
    "        shutil.move(src, dst)\n",
    "\n",
    "    # Remove pasta antiga da classe\n",
    "    os.rmdir(cls_dir)\n",
    "\n",
    "print(\"✅ Divisão finalizada: 80% treino, 20% validação em subpastas por classe.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307f8541-aaeb-40e2-8183-50fc0a5a5114",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ─── Configurações ──────────────────────────────────────────────\n",
    "DEVICE      = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ALPHABET    = \"abcdefghijklmnopqrstuvwxyz0123456789\"\n",
    "NUM_CLASSES = len(ALPHABET)\n",
    "BATCH_SIZE  = 64\n",
    "EPOCHS      = 20\n",
    "LR          = 1e-3\n",
    "\n",
    "# ─── Transforms ─────────────────────────────────────────────────\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "val_tf = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# ─── Datasets & Loaders ────────────────────────────────────────\n",
    "train_ds = ImageFolder(\"TextBasedWave/chars_by_class/train\", transform=train_tf)\n",
    "val_ds   = ImageFolder(\"TextBasedWave/chars_by_class/val\",   transform=val_tf)\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=4)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "# ─── Modelo CNN + LSTM ─────────────────────────────────────────\n",
    "class CharCNN_LSTM(nn.Module):\n",
    "    def __init__(self, num_classes, lstm_hidden=256):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),              # 32→16\n",
    "            nn.Conv2d(64,128,3,padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2)               # 16→8\n",
    "        )\n",
    "        self.lstm = nn.LSTM(input_size=128*8,\n",
    "                            hidden_size=lstm_hidden,\n",
    "                            batch_first=True)\n",
    "        self.classifier = nn.Linear(lstm_hidden, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.cnn(x)              # [B,128,8,8]\n",
    "        B, C, H, W = feat.size()\n",
    "        seq = feat.permute(0,3,1,2).contiguous().view(B, W, C*H)\n",
    "        out, (hn, cn) = self.lstm(seq)  # [B, W, lstm_hidden]\n",
    "        last = out[:, -1, :]\n",
    "        return self.classifier(last)\n",
    "\n",
    "# ─── Instanciação ──────────────────────────────────────────────\n",
    "model     = CharCNN_LSTM(NUM_CLASSES).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# ─── Loop de Treino/Validação ──────────────────────────────────\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    running_loss, total, correct = 0, 0, 0\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(imgs)\n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        preds = out.argmax(1)\n",
    "        total   += labels.size(0)\n",
    "        correct += (preds == labels).sum().item()\n",
    "    train_acc = correct/total\n",
    "\n",
    "    model.eval()\n",
    "    v_total, v_correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "            out = model(imgs)\n",
    "            preds = out.argmax(1)\n",
    "            v_total   += labels.size(0)\n",
    "            v_correct += (preds == labels).sum().item()\n",
    "    val_acc = v_correct / v_total\n",
    "\n",
    "    print(f\"Ep {epoch:02d}  Loss={running_loss/len(train_loader):.3f}  \"\n",
    "          f\"TrainAcc={train_acc:.3f}  ValAcc={val_acc:.3f}\")\n",
    "\n",
    "# ─── Salvando o modelo ─────────────────────────────────────────\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "save_path = os.path.join(\"models\", \"charcnn_lstm.pt\")\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"Modelo salvo em: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f8172cd8-94fd-4a9e-a9df-6985e6f8311c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processamento de segmentação e padding concluído.\n"
     ]
    }
   ],
   "source": [
    "# ─── Configurações ──────────────────────────────────────────────\n",
    "VAL_DIR     = \"C:/Users/joao_/captcha/TextBasedWave/train\"          # Pasta com CAPTCHAs originais\n",
    "OUTPUT_DIR  = \"C:/Users/joao_/captcha/TextBasedWave/segments\"     # Pasta raiz onde cada imagem terá sua própria pasta\n",
    "MIN_W, MIN_H = 5, 10                   # Tamanho mínimo de cada segmento\n",
    "SPLIT_W     = 30                       # Largura acima da qual dividimos em dois\n",
    "TARGET_SIZE = 32                       # tamanho final com padding\n",
    "\n",
    "def get_character_boxes(img, min_w=MIN_W, min_h=MIN_H):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, bw = cv2.threshold(gray, 0, 255,\n",
    "                         cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "    opened = cv2.morphologyEx(bw, cv2.MORPH_OPEN, kernel)\n",
    "    cnts, _ = cv2.findContours(opened, cv2.RETR_EXTERNAL,\n",
    "                               cv2.CHAIN_APPROX_SIMPLE)\n",
    "    boxes = [\n",
    "        (x, y, w, h)\n",
    "        for c in cnts\n",
    "        for x, y, w, h in [cv2.boundingRect(c)]\n",
    "        if w >= min_w and h >= min_h\n",
    "    ]\n",
    "    return sorted(boxes, key=lambda b: b[0])\n",
    "\n",
    "# ─── Loop sobre cada CAPTCHA ────────────────────────────────────\n",
    "for fname in sorted(os.listdir(VAL_DIR)):\n",
    "    name, ext = os.path.splitext(fname)\n",
    "    img_path = os.path.join(VAL_DIR, fname)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(f\"[ERRO] não foi possível ler {fname}\")\n",
    "        continue\n",
    "\n",
    "    boxes = get_character_boxes(img)\n",
    "    crops = []\n",
    "    for (x, y, w, h) in boxes:\n",
    "        if w > SPLIT_W:\n",
    "            mid = w // 2\n",
    "            crops.append(img[y:y+h, x    :x+mid])\n",
    "            crops.append(img[y:y+h, x+mid:x+w])\n",
    "        else:\n",
    "            crops.append(img[y:y+h, x:x+w])\n",
    "\n",
    "    # só continua se bate com o nome\n",
    "    if len(crops) != len(name):\n",
    "        # fallback: cortar horizontalmente em len(name) partes iguais\n",
    "        h, w = img.shape[:2]\n",
    "        part_w = w // len(name)\n",
    "        crops = [img[:, i*part_w:(i+1)*part_w] for i in range(len(name))]\n",
    "\n",
    "    out_folder = os.path.join(OUTPUT_DIR, name)\n",
    "    os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "    for idx, crop in enumerate(crops, start=1):\n",
    "        h, w = crop.shape[:2]\n",
    "\n",
    "        # 1) redimensiona se maior que TARGET_SIZE, mantendo proporção\n",
    "        scale = min(1.0, TARGET_SIZE / h, TARGET_SIZE / w)\n",
    "        new_w, new_h = int(w * scale), int(h * scale)\n",
    "        if scale < 1.0:\n",
    "            crop = cv2.resize(crop, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "        else:\n",
    "            new_w, new_h = w, h\n",
    "\n",
    "        # 2) cria canvas branco 32×32\n",
    "        canvas = np.ones((TARGET_SIZE, TARGET_SIZE, 3), dtype=crop.dtype) * 255\n",
    "\n",
    "        # 3) centraliza\n",
    "        y_off = (TARGET_SIZE - new_h) // 2\n",
    "        x_off = (TARGET_SIZE - new_w) // 2\n",
    "        canvas[y_off:y_off+new_h, x_off:x_off+new_w] = crop\n",
    "\n",
    "        # 4) salva\n",
    "        out_path = os.path.join(out_folder, f\"{idx:02d}.png\")\n",
    "        cv2.imwrite(out_path, canvas)\n",
    "\n",
    "print(\"Processamento de segmentação e padding concluído.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602bd415-21d8-4d45-bd15-40019b9b625a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "# ── Configurações ────────────────────────────────────────────────\n",
    "BASE_FOLDER    = \"TextBasedWave/segments\"\n",
    "MODEL_PATH     = \"models/charcnn_lstm.pt\"\n",
    "DEVICE         = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "EXTENSIONS     = (\".png\", \".jpg\", \".jpeg\")\n",
    "\n",
    "# ── Carrega modelo ───────────────────────────────────────────────\n",
    "model = CharCNN_LSTM(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "# ── Índice→rótulo ────────────────────────────────────────────────\n",
    "train_ds    = ImageFolder(\"TextBasedWave/chars_by_class/train\", transform=train_tf)\n",
    "class_names = train_ds.classes\n",
    "\n",
    "# ── Transform de inferência ───────────────────────────────────────\n",
    "infer_tf = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "def prepare_img(gray_np):\n",
    "    return infer_tf(gray_np)\n",
    "\n",
    "# ── Inicializa contadores ────────────────────────────────────────\n",
    "total_sequences        = 0\n",
    "correct_sequences      = 0\n",
    "overall_char_correct   = 0\n",
    "overall_char_total     = 0\n",
    "\n",
    "# ── Loop em cada CAPTCHA (pasta) ────────────────────────────────\n",
    "for label in sorted(os.listdir(BASE_FOLDER)):\n",
    "    folder = os.path.join(BASE_FOLDER, label)\n",
    "    if not os.path.isdir(folder):\n",
    "        continue\n",
    "\n",
    "    total_sequences += 1\n",
    "    seq_correct = 0\n",
    "    seq_total   = 0\n",
    "\n",
    "    # percorre os segmentos dessa pasta\n",
    "    for fname in sorted(os.listdir(folder)):\n",
    "        if not fname.lower().endswith(EXTENSIONS):\n",
    "            continue\n",
    "\n",
    "        # determina o caractere “verdadeiro” pelo índice do arquivo\n",
    "        seg_idx   = int(os.path.splitext(fname)[0]) - 1\n",
    "        true_char = label[seg_idx]\n",
    "\n",
    "        # inferência\n",
    "        gray      = cv2.imread(os.path.join(folder, fname), cv2.IMREAD_GRAYSCALE)\n",
    "        inp       = prepare_img(gray).unsqueeze(0).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            out       = model(inp)\n",
    "            pred_char = class_names[out.argmax(dim=1).item()]\n",
    "\n",
    "        # atualiza contagens de segmento\n",
    "        is_corr = (pred_char == true_char)\n",
    "        seq_correct += is_corr\n",
    "        seq_total   += 1\n",
    "        overall_char_correct += is_corr\n",
    "        overall_char_total   += 1\n",
    "\n",
    "    # se todos os segmentos ficaram corretos, conta como sequência certa\n",
    "    if seq_correct == seq_total and seq_total > 0:\n",
    "        correct_sequences += 1\n",
    "\n",
    "# ── Cálculo das métricas ────────────────────────────────────────\n",
    "sequence_accuracy  = correct_sequences / total_sequences if total_sequences else 0\n",
    "character_accuracy = overall_char_correct / overall_char_total if overall_char_total else 0\n",
    "\n",
    "# ── Impressão dos resultados ────────────────────────────────────\n",
    "print(f\"Acurácia de sequência (todas as letras corretas): \"\n",
    "      f\"{correct_sequences}/{total_sequences} = {sequence_accuracy:.2%}\")\n",
    "print(f\"Acurácia de caractere (individual): \"\n",
    "      f\"{overall_char_correct}/{overall_char_total} = {character_accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0ec6a0be-6968-408d-bef4-8979ecc72bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Configurações ────────────────────────────────────────────────\n",
    "BASE_FOLDER    = \"TextBasedWave/segments\"\n",
    "DATA_DIR       = \"TextBasedWave/chars_by_class\"              # seu diretório de treino\n",
    "PROJECT        = \"runs/captcha_wave_yolo\"\n",
    "EXP_NAME       = \"exp\"\n",
    "DEVICE         = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "EXTENSIONS     = (\".png\", \".jpg\", \".jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9417b103-b93f-485a-97de-c15e15a93e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolo11n-cls')\n",
    "model.train(\n",
    "    data=DATA_DIR,\n",
    "    epochs=50,\n",
    "    imgsz=32,\n",
    "    batch=64,\n",
    "    lrf=1e-3,\n",
    "    project=PROJECT,\n",
    "    name=EXP_NAME\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bec669-da08-4f68-a31d-5d650114a4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 2) CARREGA O MODELO TREINADO ────────────────────────────────\n",
    "best_weight = os.path.join(PROJECT, EXP_NAME, \"weights\", \"best.pt\")\n",
    "\n",
    "model = YOLO(best_weight)\n",
    "\n",
    "class_names = [model.names[i] for i in sorted(model.names)]\n",
    "\n",
    "\n",
    "# ── Função de predição para cada segmento ──────────────────────\n",
    "\n",
    "\n",
    "def predict_char(segment_path):\n",
    "    results = model.predict(\n",
    "        source=segment_path,\n",
    "        imgsz=32,\n",
    "        device=DEVICE,\n",
    "        verbose=False\n",
    "    )\n",
    "    # 1) acessa o tensor interno (torch.Tensor)\n",
    "    probs_tensor = results[0].probs.data  \n",
    "    # 2) move pra CPU e converte pra numpy de verdade\n",
    "    probs_array  = probs_tensor.cpu().numpy()  \n",
    "    # 3) pega o índice do valor máximo\n",
    "    idx = int(probs_array.argmax())\n",
    "    # 4) retorna o nome da classe\n",
    "    return class_names[idx]\n",
    "\n",
    "# ── 3) INFERÊNCIA & MÉTRICAS ────────────────────────────────────\n",
    "total_seq      = 0  # número de pastas processadas\n",
    "correct_seq    = 0  # quantas tiveram todos os segmentos corretos\n",
    "total_chars    = 0  # total de segmentos\n",
    "correct_chars  = 0  # total de segmentos corretos\n",
    "\n",
    "for label in sorted(os.listdir(BASE_FOLDER)):\n",
    "    folder = os.path.join(BASE_FOLDER, label)\n",
    "    if not os.path.isdir(folder):\n",
    "        continue\n",
    "\n",
    "    total_seq += 1\n",
    "    seq_preds = []\n",
    "\n",
    "    # percorre cada arquivo de segmento\n",
    "    for fname in sorted(os.listdir(folder)):\n",
    "        if not fname.lower().endswith(EXTENSIONS):\n",
    "            continue\n",
    "\n",
    "        seg_idx   = int(os.path.splitext(fname)[0]) - 1\n",
    "        true_char = label[seg_idx]\n",
    "\n",
    "        path      = os.path.join(folder, fname)\n",
    "        pred_char = predict_char(path)\n",
    "\n",
    "        seq_preds.append((true_char, pred_char))\n",
    "        total_chars += 1\n",
    "        if pred_char == true_char:\n",
    "            correct_chars += 1\n",
    "\n",
    "    # se todos os pares (true,pred) baterem → sequência correta\n",
    "    if all(t == p for t, p in seq_preds) and seq_preds:\n",
    "        correct_seq += 1\n",
    "\n",
    "# ── 4) RESULTADOS ───────────────────────────────────────────────\n",
    "seq_acc  = correct_seq / total_seq    if total_seq  else 0\n",
    "char_acc = correct_chars / total_chars if total_chars else 0\n",
    "\n",
    "print(f\"Acurácia de sequência (tudo certo): {correct_seq}/{total_seq} = {seq_acc:.2%}\")\n",
    "print(f\"Acurácia de caractere (isolado):   {correct_chars}/{total_chars} = {char_acc:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6125cdd-ffae-49c6-b400-fd1e470564a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# ── 0) Defina DATA_DIR e carregue o dataset para descobrir num_classes ──\n",
    "DATA_DIR = \"../TextBasedWave/chars_by_class\"\n",
    "train_tf = transforms.Compose([transforms.Resize((32,32)),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize([0.485,0.456,0.406],\n",
    "                                                    [0.229,0.224,0.225])])\n",
    "train_ds = datasets.ImageFolder(os.path.join(DATA_DIR, \"train\"), transform=train_tf)\n",
    "num_classes = len(train_ds.classes)  # ex: 36\n",
    "\n",
    "# ── 1) Definição da classe sem usar valor padrão indefinido ───────────\n",
    "class TemporalResNet50(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(TemporalResNet50, self).__init__()\n",
    "        base_model = models.resnet50()\n",
    "        self.backbone = nn.Sequential(*list(base_model.children())[:-2])\n",
    "        self.lstm     = nn.LSTM(input_size=2048, hidden_size=256,\n",
    "                                 num_layers=1, batch_first=True,\n",
    "                                 bidirectional=True)\n",
    "        self.classifier = nn.Linear(256 * 2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)          # [B, 2048, H, W]\n",
    "        b, c, h, w = x.size()\n",
    "        x = x.permute(0, 2, 3, 1).contiguous()  # [B, H, W, C]\n",
    "        x = x.view(b, h * w, c)                # [B, T, C]\n",
    "        x, _ = self.lstm(x)                    # [B, T, 512]\n",
    "        x = x[:, -1, :]                        # último timestep\n",
    "        return self.classifier(x)\n",
    "\n",
    "# ── 2) Instancie o modelo passando num_classes ────────────────────────\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TemporalResNet50(num_classes=num_classes).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c74837-e67a-402e-89a0-ebd346ee02c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── CÉLULA: TREINAMENTO DO TemporalResNet50 ────────────────────────\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ── Configurações ─────────────────────────────────────────────────\n",
    "DATA_DIR      = \"TextBasedWave/chars_by_class\"                # estrutura: chars_by_class/train e chars_by_class/val\n",
    "PROJECT       = \"models/captcha_Wave_resnet50\"\n",
    "EXP_NAME      = \"exp\"\n",
    "DEVICE        = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "num_epochs    = 100\n",
    "batch_size    = 64\n",
    "learning_rate = 1e-3\n",
    "patience      = 15\n",
    "gamma         = 0.97    # para ExponentialLR\n",
    "\n",
    "# ── Transforms ────────────────────────────────────────────────────\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "])\n",
    "val_tf   = transforms.Compose([\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "# ── Datasets & DataLoaders ────────────────────────────────────────\n",
    "train_ds   = datasets.ImageFolder(os.path.join(DATA_DIR, \"train\"), transform=train_tf)\n",
    "val_ds     = datasets.ImageFolder(os.path.join(DATA_DIR, \"val\"),   transform=val_tf)\n",
    "trainloader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=4, pin_memory=True)\n",
    "testloader  = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# ── Diretórios de saída ───────────────────────────────────────────\n",
    "weights_dir = os.path.join(PROJECT, EXP_NAME, \"weights\")\n",
    "os.makedirs(weights_dir, exist_ok=True)\n",
    "\n",
    "# ── Modelo, Otimizador, Scheduler, Critério ────────────────────────\n",
    "model     = TemporalResNet50(num_classes=len(train_ds.classes)).to(DEVICE)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# ── Loop de Treino com Early Stopping ──────────────────────────────\n",
    "best_val_acc     = 0.0\n",
    "epochs_no_improve = 0\n",
    "best_state_dict  = None\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    running_loss, running_corrects, running_total = 0.0, 0, 0\n",
    "    \n",
    "    for images, labels in tqdm(trainloader, desc=f\"[Epoch {epoch}] Treino\", leave=False):\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss     += loss.item() * images.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        running_corrects += (preds == labels).sum().item()\n",
    "        running_total    += labels.size(0)\n",
    "    \n",
    "    train_loss = running_loss / running_total\n",
    "    train_acc  = 100 * running_corrects / running_total\n",
    "    \n",
    "    # --- Validação ---\n",
    "    model.eval()\n",
    "    val_corrects, val_total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(testloader, desc=f\"[Epoch {epoch}] Validação\", leave=False):\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            val_corrects += (preds == labels).sum().item()\n",
    "            val_total    += labels.size(0)\n",
    "    \n",
    "    val_acc = 100 * val_corrects / val_total\n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch:2d} | \"\n",
    "          f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | \"\n",
    "          f\"Val Acc: {val_acc:.2f}%\")\n",
    "    \n",
    "    # Early Stopping\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc      = val_acc\n",
    "        epochs_no_improve = 0\n",
    "        best_state_dict   = model.state_dict()\n",
    "        torch.save(best_state_dict, os.path.join(weights_dir, \"best.pth\"))\n",
    "        print(f\"📈 Nova melhor Val Acc: {best_val_acc:.2f}% — modelo salvo.\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"⏸️ Sem melhora por {epochs_no_improve} época(s).\")\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"🛑 Early stopping ativado após {patience} épocas sem melhora.\")\n",
    "            break\n",
    "\n",
    "# ── Restaurar melhor modelo ───────────────────────────────────────\n",
    "model.load_state_dict(best_state_dict)\n",
    "print(\"✔️ Treinamento concluído. Melhor modelo carregado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9191592-d759-4690-85d9-e9f9d86c544f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── CÉLULA: VALIDAÇÃO SEGMENTO-A-SEGMENTO COM TemporalResNet50 ──\n",
    "\n",
    "# ── 1) Configurações ─────────────────────────────────────────────\n",
    "BASE_FOLDER    = \"TextBasedWave/segments\"               # pastas com rótulos de sequência\n",
    "EXTENSIONS     = (\".png\", \".jpg\", \".jpeg\")\n",
    "best_model_path = \"models/captcha_Wave_resnet50/exp/weights/best.pth\"         # ajuste para o seu caminho\n",
    "device         = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ── 2) Carrega o modelo treinado ─────────────────────────────────\n",
    "model = TemporalResNet50(num_classes=num_classes).to(device)\n",
    "model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# ── 3) Transforms de validação (mesmo padrão do treino) ──────────\n",
    "val_tf = transforms.Compose([\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                         std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "# ── 4) Função de predição para um segmento ───────────────────────\n",
    "def predict_char(segment_path):\n",
    "    img = Image.open(segment_path).convert(\"RGB\")\n",
    "    x   = val_tf(img).unsqueeze(0).to(device)            # [1,C,H,W]\n",
    "    with torch.no_grad():\n",
    "        logits = model(x)                                # [1,num_classes]\n",
    "        idx    = int(logits.argmax(dim=1).cpu().item())\n",
    "    return train_ds.classes[idx]                         # lista de classes do ImageFolder\n",
    "\n",
    "# ── 5) Inferência & métricas ────────────────────────────────────\n",
    "total_seq     = 0   # total de sequências (pastas)\n",
    "correct_seq   = 0   # quantas sequências tiveram TODOS os chars corretos\n",
    "total_chars   = 0   # total de segmentos avaliados\n",
    "correct_chars = 0   # total de segmentos corretos\n",
    "\n",
    "for label in sorted(os.listdir(BASE_FOLDER)):\n",
    "    folder = os.path.join(BASE_FOLDER, label)\n",
    "    if not os.path.isdir(folder):\n",
    "        continue\n",
    "\n",
    "    total_seq += 1\n",
    "    seq_preds = []\n",
    "\n",
    "    for fname in sorted(os.listdir(folder)):\n",
    "        if not fname.lower().endswith(EXTENSIONS):\n",
    "            continue\n",
    "\n",
    "        seg_idx    = int(os.path.splitext(fname)[0]) - 1\n",
    "        true_char  = label[seg_idx]\n",
    "        path       = os.path.join(folder, fname)\n",
    "        pred_char  = predict_char(path)\n",
    "\n",
    "        seq_preds.append((true_char, pred_char))\n",
    "        total_chars += 1\n",
    "        if pred_char == true_char:\n",
    "            correct_chars += 1\n",
    "\n",
    "    if seq_preds and all(t == p for t, p in seq_preds):\n",
    "        correct_seq += 1\n",
    "\n",
    "# ── 6) Resultados ────────────────────────────────────────────────\n",
    "seq_acc  = correct_seq   / total_seq   if total_seq   else 0\n",
    "char_acc = correct_chars / total_chars if total_chars else 0\n",
    "\n",
    "print(f\"Acurácia de sequência (tudo certo): {correct_seq}/{total_seq} = {seq_acc:.2%}\")\n",
    "print(f\"Acurácia de caractere (isolado):   {correct_chars}/{total_chars} = {char_acc:.2%}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
